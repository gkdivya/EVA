{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of PyTorch101.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkdivya/EVA/blob/main/PyTorch101.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_kYM3ylzYo1Q"
      },
      "source": [
        "![PyTorch](https://devblogs.nvidia.com/wp-content/uploads/2017/04/pytorch-logo-dark.png)\n",
        "\n",
        "An open source machine learning framework that accelerates the path from research prototyping to production deployment.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WcVqSTrWY6oz"
      },
      "source": [
        "# Tensor - Pytorch's core data structure\n",
        "\n",
        "In Python we can create lists, lists of lists, lists of lists and so on. In NumPy there is a `numpy.ndarray` which represents `n`- dimensional array. In math there is a special name for the generalization of vectors and matrices to a higher dimensional space - a tensor\n",
        "\n",
        "Tensor is an entity with a defined number of dimensions called an order (rank). \n",
        "\n",
        "**Scalar** can be considered as a rank-0-tensor. \n",
        "\n",
        "**Vector** can be introduced as a rank-1-tensor. \n",
        "\n",
        "**Matrices** can be considered as a rank-2-tensor.\n",
        "\n",
        "# Tensor Basics\n",
        "\n",
        "Let's import the torch module first."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-oFVL2tYYqp"
      },
      "source": [
        "import numpy as np\n",
        "import torch"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uGxuR5IEaFJa"
      },
      "source": [
        "## Tensor Creation\n",
        "Let's view examples of matrices and tensors generation\n",
        "\n",
        "2-dimensional (rank-2) tensor of zeros:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "897JQc25aD3E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "440b9c18-58f8-4011-dea0-fd49aa0281fd"
      },
      "source": [
        "torch.zeros(3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.],\n",
              "        [0., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pujmpEBhaPRA"
      },
      "source": [
        "Random rank-3 tensor:\n",
        "_read the print below and convince yourself how this is a rank-3-tensor and learn what those 2, 3, 4 values are there for_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBrznTNhaOL7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "b8766972-2d0b-4b41-cd3b-b66dbbb56c40"
      },
      "source": [
        "torch.rand(2, 3, 4)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[0.7813, 0.2514, 0.4112, 0.3669],\n",
              "         [0.2603, 0.0648, 0.4038, 0.4019],\n",
              "         [0.9940, 0.7059, 0.0028, 0.7583]],\n",
              "\n",
              "        [[0.4199, 0.7931, 0.7042, 0.5402],\n",
              "         [0.1671, 0.5256, 0.1711, 0.9451],\n",
              "         [0.1067, 0.8843, 0.5401, 0.9266]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kO4fIr15asdi"
      },
      "source": [
        "I am hoping you have noticed 4-elements in a row, 3 rows making one block and there are 2 blocks. \n",
        "\n",
        "Random rank-4-tensor:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiCLvMGCaVZ3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "d5c01ff4-23be-4084-a143-b3e639ae1d5f"
      },
      "source": [
        "torch.rand(2, 2, 2, 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.4238, 0.5172, 0.5660],\n",
              "          [0.7864, 0.2312, 0.8998]],\n",
              "\n",
              "         [[0.2318, 0.1947, 0.7657],\n",
              "          [0.6428, 0.7590, 0.3680]]],\n",
              "\n",
              "\n",
              "        [[[0.0699, 0.9107, 0.4747],\n",
              "          [0.0936, 0.4158, 0.0542]],\n",
              "\n",
              "         [[0.0143, 0.0524, 0.7135],\n",
              "          [0.9181, 0.2190, 0.3682]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF6VL68s3AMV"
      },
      "source": [
        "## Question 1:\n",
        "\n",
        "How many dimensions are there in a tensor defined as below?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IbXcI3x3Ibt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "917e866e-9ad8-4b5a-f190-72ba415c87e7"
      },
      "source": [
        "torch.rand(1, 1, 1, 1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[0.4529]]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2zC_MhOLaWA"
      },
      "source": [
        "a = torch.rand(1, 1, 1, 1)\n",
        "a\n",
        "a.dim()\n",
        " Ans : 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zdKjWmvOKpm0",
        "outputId": "20fec327-832f-4ee7-a108-f86af4acc87e"
      },
      "source": [
        "a = torch.rand(1, 1, 1, 1)\n",
        "a\n",
        "a.dim()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_x-86B8gqik"
      },
      "source": [
        "**Difference between** `torch.Tensor` **and** `torch.from_numpy`\n",
        "\n",
        "Pytorch aims to be an effective library for computations. What does it mean? It means that pytorch avoids memory copying if it can. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHCKDGpygn_d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "9d4a2409-7d5f-488c-d06b-a672c3141b76"
      },
      "source": [
        "numpy_array[0] = 10\n",
        "\n",
        "print('Array:  ', numpy_array)\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Tensor: ', tensor_from_array_v2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Array:   [10  2]\n",
            "Tensor:  tensor([1, 2])\n",
            "Tensor:  tensor([10,  2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-CKtdNRM3SMp"
      },
      "source": [
        "## Question 2:\n",
        "\n",
        "Assume that we moved our complete (cats vs dogs) image dataset to numpy arrays. Then we use torch.from_numpy to convert these images to tensor. Then we apply a specific data augmentation strategy called \"CutOut\" which blocks a portion of the image directly on these tensors. What will happen to the accuracy of a model trained on this strategy compared to the one without this strategy? CutOut strategy is shown below: \n",
        "\n",
        "![CutOut](https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcSnSyN835AmtQPKQbPjDHX-FmshNilbtexX95cRGQPwl56QCGDn)\n",
        "\n",
        "## Question 3:\n",
        "Why do you think we are observing this behavior?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmnWJleqL8Nl"
      },
      "source": [
        "Answer for 2:\n",
        "\n",
        "Cutout is one of the data augmentation techniques used in Image processing algorithm.This technique randomly masks out square regions of input during training.It will improve the robustness and overall performance of convolutional neural networks.The accurracy of the model will get slightly improved compared to training the model without mask out the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZq7O-aihSOA"
      },
      "source": [
        "We have two different ways to create tensor from its NumPy counterpart - one copies memory and another one shares the same underlying storage. It works in the opposite way:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNFOwV8EhPwQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "outputId": "5c3662a8-6726-472a-b7ad-c7762136f687"
      },
      "source": [
        "array_from_tensor = tensor_from_array.numpy()\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)\n",
        "\n",
        "tensor_from_array[0] = 11\n",
        "print('Tensor: ', tensor_from_array)\n",
        "print('Array: ', array_from_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor:  tensor([1, 2])\n",
            "Array:  [1 2]\n",
            "Tensor:  tensor([11,  2])\n",
            "Array:  [11  2]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UM9ytbvKhtCw"
      },
      "source": [
        "## Data types\n",
        "\n",
        "The basic data type of all Deep Learning-related operations is float, but sometimes you may need something else. Pytorch support different number types for its tensors the same way NumPy does it - by specifying the data type on tensor creation or via casting. Ths full list of supported data types can be found [here](https://pytorch.org/docs/stable/tensors.html). "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bd6WkzJ4hpYi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "158763d1-a5c2-4a05-c8d0-447a87063a6b"
      },
      "source": [
        "tensor = torch.zeros(2, 2)\n",
        "print('Tensor with default type: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.float16)\n",
        "print('Tensor with 16-bit float: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.int16)\n",
        "print('Tensor with integers: ', tensor)\n",
        "tensor = torch.zeros(2, 2, dtype=torch.bool)\n",
        "print('Tensor with boolean data: ', tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor with default type:  tensor([[0., 0.],\n",
            "        [0., 0.]])\n",
            "Tensor with 16-bit float:  tensor([[0., 0.],\n",
            "        [0., 0.]], dtype=torch.float16)\n",
            "Tensor with integers:  tensor([[0, 0],\n",
            "        [0, 0]], dtype=torch.int16)\n",
            "Tensor with boolean data:  tensor([[False, False],\n",
            "        [False, False]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9F4Dkdr40TE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Question 4:\n",
        "We saw above that some times numpy and tensors share same storage and changing one changes the other. \n",
        "If we define a rank-2-tensor with ones (dtype of f16), and then convert it into a numpy data type using tensor.numpy() and store it in a variable called \"num\", and then we perform this operation `num = num * 0.5`, will the original tensor have 1.0s or 0.5s as its element values? \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kekim9X2PrOS",
        "outputId": "002600c3-3161-4c5a-dd84-935c6633f34b"
      },
      "source": [
        "b= torch.ones(2, 3,dtype=torch.float16)\n",
        "b\n",
        "num = b.numpy()\n",
        "num = num * 0.5\n",
        "print(num)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.5 0.5 0.5]\n",
            " [0.5 0.5 0.5]]\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4i2hv2thRlmu"
      },
      "source": [
        "Yes, The original tensor will have 1.0s as its element values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OiQt8Mmm51OE"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 5: \n",
        "If the operation `num = num*5` is changed to `num[:] = num*5` will the original tensor have 1.0s or 0.5s as its element values? \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cCerniUOSMU9",
        "outputId": "082978ec-f8e4-49ce-c39e-c16de442a097"
      },
      "source": [
        "b= torch.ones(2, 3,dtype=torch.float16)\n",
        "b\n",
        "num = b.numpy()\n",
        "num[:] = num*5\n",
        "print(num)\n",
        "print(b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[5. 5. 5.]\n",
            " [5. 5. 5.]]\n",
            "tensor([[5., 5., 5.],\n",
            "        [5., 5., 5.]], dtype=torch.float16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhN0S5dFSa5q"
      },
      "source": [
        "The original tensor will get updated to 5.Os as its element values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzh8UB8KiVmb"
      },
      "source": [
        "## Indexing\n",
        "\n",
        "Tensor provides access to its elements via the same `[]` operation as a regular python list or NumPy array. However, as you may recall from NumPy usage, the full power of math libraries is accessible only via vectorized operations, i.e. operations without explicit looping over all vector elements in python and using implicit optimized loops in C/C++/CUDA/Fortran/etc. available via special function calls. Pytorch employs the same paradigm and provides a wide range of vectorized operations. Let's take a look at some examples. \n",
        "\n",
        "Joining a list of tensors together with `torch.cat`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GMaCDKPhiUAb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "bc0a7e9b-7197-402e-c826-925b38bd4a08"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "print(torch.cat((a, b), dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0., 0.],\n",
            "        [0., 0.],\n",
            "        [0., 0.],\n",
            "        [1., 1.],\n",
            "        [1., 1.],\n",
            "        [1., 1.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bj4aeE86zdH"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 6: \n",
        "Is the transpose of concatenated a & b tensor on dimension 1, same as the contatenated tensor of a & b on dimension 0? \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NNnDdi-S0qD",
        "outputId": "d7251285-b9f9-4ece-a698-5359b0ffe724"
      },
      "source": [
        "a = torch.zeros(3, 2)\n",
        "b = torch.ones(3, 2)\n",
        "c = torch.cat((a, b), dim=1)\n",
        "c.t()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0., 0., 0.],\n",
              "        [0., 0., 0.],\n",
              "        [1., 1., 1.],\n",
              "        [1., 1., 1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz5_zQ5zUWyu"
      },
      "source": [
        "No, both are different."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0TXNne69j7LP"
      },
      "source": [
        "Indexing with another tenxor/array:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KiE-Fsi4jVd6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "4d151099-547f-4308-a82c-b7a9d7091e4b"
      },
      "source": [
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) > 5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "indices = torch.arange(start=0, end=10) %5\n",
        "print(indices)\n",
        "print(a[indices])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "[False False False False False False  True  True  True  True]\n",
            "tensor([6, 7, 8, 9])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n",
            "tensor([0, 1, 2, 3, 4, 0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS4dnlu47WQu"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 7:\n",
        "\n",
        "`a` is defined as `torch.arange(start=0, end=10)`. We will create `b` using the two operations as below. In both cases do we get the same value?\n",
        "\n",
        "\n",
        "1.   indices variable created by the modulo operation on arange between 0 and 10. Then a new varialble `b` is created from `a` using the last 5 elements of indices. \n",
        "2.   indices variable created by the modulo operation on arange betwenn 1 and 11. Then a new varialble `b` is created from `a` using the last 5 elements of indices. \n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WF3i2yaeUnqQ"
      },
      "source": [
        "# Q1\n",
        "a = torch.arange(start=0, end=10)\n",
        "indices = np.arange(0, 10) > 5\n",
        "print(a)\n",
        "print(indices)\n",
        "print(a[indices])\n",
        "\n",
        "indices = torch.arange(start=0, end=10) %5\n",
        "print(indices)\n",
        "print(a[indices])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eQ4ZCVsTk-KH"
      },
      "source": [
        "What should we do if we have, say, rank-2-tensor and want to select only some rows?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBDB5pvGWCjP"
      },
      "source": [
        "We should use Numpy indexing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_GtRpotjkt1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72ac23f4-5a59-4e54-b6e3-ba295a74cb38"
      },
      "source": [
        "tensor = torch.rand((5, 3))\n",
        "rows = torch.tensor([0, 2])\n",
        "print(tensor)\n",
        "tensor[rows]\n",
        "loc = torch.ByteTensor([0,0,1,0,0])\n",
        "y = tensor[loc]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8857, 0.8964, 0.9016],\n",
            "        [0.5287, 0.0971, 0.9865],\n",
            "        [0.7292, 0.8895, 0.2685],\n",
            "        [0.6797, 0.7552, 0.4649],\n",
            "        [0.1038, 0.1239, 0.1982]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:6: UserWarning: indexing with dtype torch.uint8 is now deprecated, please use a dtype torch.bool instead. (Triggered internally at  /pytorch/aten/src/ATen/native/IndexingUtils.h:30.)\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zIJnr_N2_Qaf"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 8: \n",
        "\n",
        "Consider a tensor defined as `torch.rand((6, 5))`. Is the shape of the new tensor created by taking the 0th, 2nd and 4th row of the old tensor same as the shape of the a newer tensor created by taking the 0th, 2nd and 4th row of the old tensor after transposing it by operation `torch.transpose(tensor, 0, 1)` ?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TevqKIOd-bKl"
      },
      "source": [
        "No. After transposing the shape of the old tensor will be (5,6)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZLCQwTc-5hh",
        "outputId": "36c83c1b-e8fc-45c5-f8ba-e074c93f9e6e"
      },
      "source": [
        " x = torch.randn(6, 5)\n",
        " x\n",
        "torch.transpose(x, 0, 1)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 3.3519,  0.1645, -1.0887,  1.4452, -0.5557, -1.9987],\n",
              "        [-0.1325, -1.5108,  0.2449,  0.7533,  0.0960,  1.0222],\n",
              "        [-1.9845, -0.5067,  1.2984,  1.7765, -0.5529, -0.8758],\n",
              "        [-0.1629,  2.8487,  1.1766, -1.1894, -1.1571,  1.0520],\n",
              "        [ 0.1922, -1.5049,  0.9775,  0.7424,  0.8044,  0.9627]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDzFMkslU0b"
      },
      "source": [
        "## Tensor Shapes\n",
        "\n",
        "Reshaping a tensor is a frequently used operation. We can change the shape of a tensor without the memory copying overhead. There are two methods for that: `reshape` and `view`. \n",
        "\n",
        "The difference is the following: \n",
        "\n",
        "\n",
        "*   view tries to return a tensor, and it shares the same memory with the original tensor. In case, if it cannot reuse the same memory due to [some reason](https://pytorch.org/docs/stable/tensors.html?highlight=view#torch.Tensor.view), it just fails. \n",
        "*   reshape always returns the tensor with the desired shape and tries to reuse the memory. If it cannot, it creates a copy\n",
        "\n",
        "Let's see with the help of an example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HClDkqLLlMJh",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "outputId": "703bf39f-96e5-4990-90bb-1b59b96a01fb"
      },
      "source": [
        "tensor = torch.rand(2, 3, 4)\n",
        "print('Pointer to data: ', tensor.data_ptr())\n",
        "print('Shape: ', tensor.shape)\n",
        "\n",
        "reshaped = tensor.reshape(24)\n",
        "\n",
        "view = tensor.view(3, 2, 4)\n",
        "print('Reshaped tensor - pointer to data', reshaped.data_ptr())\n",
        "print('Reshaped tensor shape ', reshaped.shape)\n",
        "\n",
        "print('Viewed tensor - pointer to data', view.data_ptr())\n",
        "print('Viewed tensor shape ', view.shape)\n",
        "\n",
        "assert tensor.data_ptr() == view.data_ptr()\n",
        "\n",
        "assert np.all(np.equal(tensor.numpy().flat, reshaped.numpy().flat))\n",
        "\n",
        "print('Original stride: ', tensor.stride())\n",
        "print('Reshaped stride: ', reshaped.stride())\n",
        "print('Viewed stride: ', view.stride())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pointer to data:  54042240\n",
            "Shape:  torch.Size([2, 3, 4])\n",
            "Reshaped tensor - pointer to data 54042240\n",
            "Reshaped tensor shape  torch.Size([24])\n",
            "Viewed tensor - pointer to data 54042240\n",
            "Viewed tensor shape  torch.Size([3, 2, 4])\n",
            "Original stride:  (12, 4, 1)\n",
            "Reshaped stride:  (1,)\n",
            "Viewed stride:  (8, 4, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIN5jSppm4yC"
      },
      "source": [
        "The basic rule about reshaping the tensor is definitely that you cannot change the total number of elements in it, so the product of all tensor's dimensions should always be the same. It gives us the ability to avoid specifying one dimension when reshaping the tensor - Pytorch can calculate it for us:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3D19ERFmzOl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "b49f6393-7a79-4da7-bb31-b5d8cd885e3a"
      },
      "source": [
        "print(tensor.reshape(3, 2, 4).shape)\n",
        "print(tensor.reshape(3, 2, -1).shape)\n",
        "print(tensor.reshape(3, -1, 4).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n",
            "torch.Size([3, 2, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ObgCQKUiETak"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## Question 9:\n",
        "\n",
        "Consider a tensor `a` created with [1, 2, 3] and [1, 2, 3] of size (2, 3) is reshaped with operation `.reshape(-1, 2)`. Also consider a tensor `b` created with [[2, 1]] and of size (1, 2), later operated with `view(2, -1)` operation. \n",
        "\n",
        "If we do a dot product of a and b (using `torch.mm`) and perform the sum of all the elements (using `torch.sum`) what do we get? (enter int value without any decimal point in the quiz)\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hLAMHGACsS-q",
        "outputId": "1ed564a1-ab2c-45b8-eb1a-80bfef2c5ea6"
      },
      "source": [
        "a = torch.FloatTensor([[1, 2, 3],\n",
        "              [1,2,3]])\n",
        "a.shape\n",
        "a.reshape(-1,2)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 2.],\n",
              "        [3., 1.],\n",
              "        [2., 3.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBC87v7TvKkL",
        "outputId": "11624a78-8b93-4e40-809b-6060c8f0699a"
      },
      "source": [
        "b = torch.FloatTensor([[2,1]])\n",
        "b.shape\n",
        "b.reshape(2,-1)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.],\n",
              "        [1.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 167
        },
        "id": "gO_Akt8-ypcH",
        "outputId": "7228b7bb-5329-4d26-fbb0-6712161dd050"
      },
      "source": [
        "torch.matmul(a,b)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-fbff7a713ff0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x3 and 1x2)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mza7QPg3ndeV"
      },
      "source": [
        "**Alternative ways to view tensors** - `expand` or `expand_as`.\n",
        "\n",
        "\n",
        "\n",
        "*   `expand` - requires the desired shape as an input\n",
        "*   `expand_as` - uses the shape of another tensor\n",
        "\n",
        "These operations \"repeat\" tensor's values along the specified axes without actually copying the data. \n",
        "\n",
        "As the documentation says, expand:\n",
        "\n",
        "\n",
        "> returns a new view of the self tensor with singleton dimensions expanded to a larger size. Tensor can be also expanded to a larger number of dimensions, and the new ones will be appended at the front. For the new dimensions, the size cannot be set to -1. \n",
        "\n",
        "**Use case:**\n",
        "\n",
        "\n",
        "\n",
        "*   index multi-channel tensor with single-channel mask - imagine a color image with 3 channels (RGB) and binary mask for the area of interest on that image. We cannot index the image with this kind of mask directly since the dimensions are different, but we can use `expand_as` operation to create a view of the mask that has the same dimensions as the image we want to apply it to, but has not copied the data. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iz33E-V7nPQT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 596
        },
        "outputId": "8bcfc71f-b0bb-4c37-e5e0-5c4ffa38aacb"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# Create a black image\n",
        "image = torch.zeros(size=(3, 256, 256), dtype=torch.int)\n",
        "\n",
        "# Leave the borders and make the rest of the image Green\n",
        "image[1, 18:256 - 18, 18:256 - 18] = 255\n",
        "\n",
        "# Create a mask of the same size\n",
        "mask = torch.zeros(size=(256, 256), dtype=torch.bool)\n",
        "\n",
        "# Assuming the green region in the original image is the Region of interest, change the mask to white for that area\n",
        "mask[18:256 - 18, 18:256 - 18] = 1\n",
        "\n",
        "# Create a view of the mask with the same dimensions as the original image\n",
        "mask_expanded = mask.expand_as(image)\n",
        "print(mask_expanded.shape)\n",
        "\n",
        "mask_np = mask_expanded.numpy().transpose(1, 2, 0) * 255\n",
        "image_np = image.numpy().transpose(1, 2, 0)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[0, mask] += 128\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()\n",
        "\n",
        "image[mask_expanded] += 128\n",
        "image.clamp_(0, 255)\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(image_np)\n",
        "ax[1].imshow(mask_np)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 256, 256])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAC7CAYAAACend6FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiXBx0k3ptOI"
      },
      "source": [
        "In the example above, one can also find a couple of useful tricks:\n",
        "\n",
        "\n",
        "*   `clamp` method and function is a Pytorch's analogue of NumPy's `clip` function\n",
        "*   many operations on tensors have in-place form, that does not return modified data, but change values in the tensor. The in-place version of the operation has trailing underscore according to Pytorch's naming convension - in the exmaple above it is `clamp_`\n",
        "*   tensors have the same indexing as Numpy's arrays - one can use `:` seperated range, negative indexes and so on.\n",
        "\n",
        "\n",
        ".\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "# Images and their representations\n",
        "\n",
        "Now, let's discuss images, their representations and how different Python librarties work with them. \n",
        "\n",
        "Probably, the most well-known library for image loading and simple processing is [Pillow](https://pillow.readthedocs.io/en/stable/). \n",
        "\n",
        "However, many people in deep learning area stick with OpenCV for image loading and processing with some usage of another libraries when it is justified by performance/functionality. This is because OpenCV is in general much faster than the other libraries. Here you can find a couple of benchmarks: \n",
        "\n",
        "*   https://www.kaggle.com/zfturbo/benchmark-2019-speed-of-image-reading\n",
        "*   https://github.com/albumentations-team/albumentations#benchmarking-results\n",
        "\n",
        "To sum up the benchmarks above, there are two most common image formats, PNG and JPEGs. If your data is in PNG format - use OpenCV to read it. If it is in JPEG - use libturbojpeg. For image processing, use OpenCV if possible. _We will be using PIL a lot along with these._\n",
        "\n",
        "As you will read the code from others, you may find out that some of them use Pillow/something else to read data. You should know, that color image representations in OpenCV and other libraries are different - OpenCV uses \"BGR\" channel order, while others use \"RGB\" one. \n",
        "\n",
        "To change \"BRG\" <-> \"RGB\" the only thing we need to do it to change channel order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZYv4sZMmpndu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 152
        },
        "outputId": "8751abcd-fa7d-494a-83fc-65db456a2a22"
      },
      "source": [
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "\n",
        "\n",
        "bgr_image = cv2.imread('mars.jpg') \n",
        "# remember to add your own image in case you run this block, if you want to use the same image, \n",
        "# download it from: https://encrypted-tbn0.gstatic.com/images?q=tbn%3AANd9GcRCA40ftnscVzfV8ft8e7vIzQXfXeZdtco8nknJrfCUW6INI40U\n",
        "rgb_image = bgr_image[..., ::-1]\n",
        "fig, ax = plt.subplots(1, 2)\n",
        "ax[0].imshow(bgr_image)\n",
        "ax[1].imshow(rgb_image)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAACHCAYAAADtJRlTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoi4TeNBGHle"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 10:\n",
        "\n",
        "Looking at the results above it can be said that the pixel values in the blue channels would be very small compared to red channel. True/False?\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MPl1HBOcnQF"
      },
      "source": [
        "False.We can't say just by looking at the picture whether the pixel values in blue channels are small or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b3ugFd57zNwa"
      },
      "source": [
        "# Autograd\n",
        "\n",
        "Pytorch supports automatic differentiation. The module which implements this is called **AutoGrad**. It calculates the gradients and keeps track in forward and backward passes. For primitive tensors, you need to enable or disable it using the `required_grad` flag. But, for advanced tensors, it is enabled by default"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMOp4aiou6JR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "e9a22acd-21b1-427d-c1c0-90302bc1c37a"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad = True)\n",
        "print(a)\n",
        "result = a * 5\n",
        "print(result)\n",
        "\n",
        "# grad can be implicitly created only for scalar outputs\n",
        "# so let's calculate the sum here so that the output becomes a scalar and we can apply a backward pass\n",
        "mean_result = result.sum()\n",
        "print(mean_result)\n",
        "# calculate gradient\n",
        "mean_result.backward()\n",
        "# print gradient of a\n",
        "print(a.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.1420, 0.0529, 0.6277, 0.6623, 0.4401],\n",
            "        [0.0893, 0.8400, 0.5712, 0.4038, 0.1173],\n",
            "        [0.3958, 0.8571, 0.1979, 0.5202, 0.4367]], requires_grad=True)\n",
            "tensor([[0.7102, 0.2647, 3.1385, 3.3117, 2.2004],\n",
            "        [0.4464, 4.2000, 2.8562, 2.0192, 0.5864],\n",
            "        [1.9788, 4.2853, 0.9895, 2.6009, 2.1835]], grad_fn=<MulBackward0>)\n",
            "tensor(31.7716, grad_fn=<SumBackward0>)\n",
            "tensor([[5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.],\n",
            "        [5., 5., 5., 5., 5.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym0Amk2IGfLx"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "## Question 11: \n",
        "\n",
        "Why the gradient of a is all 5s above?\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PDgGq2R0k7I"
      },
      "source": [
        "As we see, Pytorch automagically calculated the gradient value for us. It looks to be the correct value - we multiplied an input by 5, so the gradient of this operation equals to 5.\n",
        "\n",
        "# Disabling Autograd for tensors\n",
        "\n",
        "We don't need to compute gradients for all the variables that are involved in the pipeline. The Pytorch API provides 2 ways to disable autograd.\n",
        "\n",
        "`detach` - returns a copy of the tensor with autograd disabled. This \n",
        "\n",
        "1.   copy is built on the same memory as the original tensor, so in-place size / stride / storage changes (such as resize_ / resizeas / set / transpose) modifications are not allowed.\n",
        "2.   torch.no_grad() - It is a context manager that allows you to guard a series of operations from autograd without creating new tensors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqVG9fQb0cLW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "2081f403-31a2-4296-c670-b899e246a8cc"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "detached_a = a.detach()\n",
        "detached_result = detached_a * 5\n",
        "result = a * 10\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uqpch2Be02J7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "0a5ee8e8-81b8-46f0-c7fc-ac406657e928"
      },
      "source": [
        "a = torch.rand((3, 5), requires_grad=True)\n",
        "with torch.no_grad():\n",
        "    detached_result = a * 5\n",
        "result = a * 10\n",
        "# we cannot do backward pass that is required for autograd using multideminsional output,\n",
        "# so let's calculate the sum here\n",
        "mean_result = result.sum()\n",
        "mean_result.backward()\n",
        "a.grad"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.],\n",
              "        [10., 10., 10., 10., 10.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vjh2rYOPJUAZ"
      },
      "source": [
        "# Custom Network\n",
        "\n",
        "A fully-connected ReLU network with one hidden layer and no biases, trained to predict y from x by minimizing squared Euclidean distance.\n",
        "\n",
        "This implementation uses PyTorch tensors to manually compute the forward pass, loss, and backward pass.\n",
        "\n",
        "A PyTorch Tensor is basically the same as a numpy array: it does not know anything about deep learning or computational graphs or gradients, and is just a generic n-dimensional array to be used for arbitrary numeric computation.\n",
        "\n",
        "The biggest difference between a numpy array and a PyTorch Tensor is that a PyTorch Tensor can run on either CPU or GPU. To run operations on the GPU, just cast the Tensor to a cuda datatype."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0nf5RaB104Vp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "c0829682-3be1-4709-dff8-2e4d2bc59e53"
      },
      "source": [
        "dtype = torch.float\n",
        "device = torch.device(\"cpu\")\n",
        "# device = torch.device(\"cuda:0\") # Uncomment this to run on GPU\n",
        "\n",
        "# N is batch size; D_in is input dimension;\n",
        "# H is hidden dimension; D_out is output dimension.\n",
        "N, D_in, H, D_out = 64, 1000, 100, 10\n",
        "\n",
        "# Create random input and output data\n",
        "x = torch.randn(N, D_in, device=device, dtype=dtype)\n",
        "y = torch.randn(N, D_out, device=device, dtype=dtype)\n",
        "\n",
        "# Randomly initialize weights\n",
        "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
        "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
        "\n",
        "learning_rate = 1e-6\n",
        "for t in range(500):\n",
        "    # Forward pass: compute predicted y\n",
        "    h = x.mm(w1)\n",
        "    h_relu = h.clamp(min=0)\n",
        "    y_pred = h_relu.mm(w2)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum().item()\n",
        "    print(t, loss)\n",
        "\n",
        "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
        "    grad_y_pred = 2*(y_pred - y)\n",
        "    grad_w2 = h_relu.t().mm(grad_y_pred)\n",
        "    grad_h_relu = grad_y_pred.mm(w2.t())\n",
        "    grad_h = grad_h_relu.clone()\n",
        "    grad_h[h < 0] = 0\n",
        "    grad_w1 = x.t().mm(grad_h)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * grad_w1\n",
        "    w2 -= learning_rate * grad_w2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0 41697068.0\n",
            "1 42741256.0\n",
            "2 45341812.0\n",
            "3 39751452.0\n",
            "4 25930328.0\n",
            "5 12725715.0\n",
            "6 5614377.5\n",
            "7 2761390.75\n",
            "8 1680575.875\n",
            "9 1209127.5\n",
            "10 951487.9375\n",
            "11 780990.3125\n",
            "12 654308.125\n",
            "13 554848.9375\n",
            "14 474434.0625\n",
            "15 408432.6875\n",
            "16 353772.0625\n",
            "17 307994.8125\n",
            "18 269352.90625\n",
            "19 236650.5625\n",
            "20 208688.625\n",
            "21 184659.71875\n",
            "22 163873.390625\n",
            "23 145837.0625\n",
            "24 130119.34375\n",
            "25 116374.53125\n",
            "26 104308.7109375\n",
            "27 93689.65625\n",
            "28 84314.09375\n",
            "29 76013.9765625\n",
            "30 68648.3515625\n",
            "31 62093.23046875\n",
            "32 56248.9140625\n",
            "33 51025.9296875\n",
            "34 46352.0078125\n",
            "35 42163.4921875\n",
            "36 38400.97265625\n",
            "37 35012.98046875\n",
            "38 31960.2578125\n",
            "39 29202.791015625\n",
            "40 26708.99609375\n",
            "41 24451.38671875\n",
            "42 22404.189453125\n",
            "43 20547.466796875\n",
            "44 18860.30078125\n",
            "45 17325.404296875\n",
            "46 15927.8154296875\n",
            "47 14653.16015625\n",
            "48 13490.51953125\n",
            "49 12431.3388671875\n",
            "50 11466.0859375\n",
            "51 10582.70703125\n",
            "52 9773.423828125\n",
            "53 9031.99609375\n",
            "54 8352.2890625\n",
            "55 7728.07421875\n",
            "56 7154.50439453125\n",
            "57 6626.9853515625\n",
            "58 6141.50048828125\n",
            "59 5694.49609375\n",
            "60 5282.9736328125\n",
            "61 4904.0185546875\n",
            "62 4554.17822265625\n",
            "63 4231.1953125\n",
            "64 3933.441650390625\n",
            "65 3658.220458984375\n",
            "66 3403.770263671875\n",
            "67 3168.24609375\n",
            "68 2950.22802734375\n",
            "69 2748.300048828125\n",
            "70 2561.19091796875\n",
            "71 2387.71044921875\n",
            "72 2226.76513671875\n",
            "73 2077.4560546875\n",
            "74 1938.790283203125\n",
            "75 1810.0057373046875\n",
            "76 1690.32373046875\n",
            "77 1579.087890625\n",
            "78 1475.653564453125\n",
            "79 1379.4122314453125\n",
            "80 1289.7012939453125\n",
            "81 1206.1904296875\n",
            "82 1128.460205078125\n",
            "83 1056.072021484375\n",
            "84 988.5911254882812\n",
            "85 925.7052612304688\n",
            "86 867.09619140625\n",
            "87 812.4027099609375\n",
            "88 761.3564453125\n",
            "89 713.7047729492188\n",
            "90 669.213134765625\n",
            "91 627.63720703125\n",
            "92 588.7909545898438\n",
            "93 552.4854125976562\n",
            "94 518.5298461914062\n",
            "95 486.77703857421875\n",
            "96 457.07135009765625\n",
            "97 429.2778625488281\n",
            "98 403.2607727050781\n",
            "99 378.90155029296875\n",
            "100 356.08843994140625\n",
            "101 334.7173156738281\n",
            "102 314.69500732421875\n",
            "103 295.92529296875\n",
            "104 278.33172607421875\n",
            "105 261.840576171875\n",
            "106 246.3705291748047\n",
            "107 231.86231994628906\n",
            "108 218.24771118164062\n",
            "109 205.46836853027344\n",
            "110 193.47393798828125\n",
            "111 182.2140655517578\n",
            "112 171.64060974121094\n",
            "113 161.7060546875\n",
            "114 152.37240600585938\n",
            "115 143.60488891601562\n",
            "116 135.3736572265625\n",
            "117 127.6404037475586\n",
            "118 120.36878967285156\n",
            "119 113.52889251708984\n",
            "120 107.09272766113281\n",
            "121 101.03926849365234\n",
            "122 95.3431167602539\n",
            "123 89.98001098632812\n",
            "124 84.93232727050781\n",
            "125 80.1795654296875\n",
            "126 75.70399475097656\n",
            "127 71.49104309082031\n",
            "128 67.51925659179688\n",
            "129 63.777496337890625\n",
            "130 60.250972747802734\n",
            "131 56.92778396606445\n",
            "132 53.795379638671875\n",
            "133 50.84176254272461\n",
            "134 48.0562744140625\n",
            "135 45.429996490478516\n",
            "136 42.954071044921875\n",
            "137 40.617462158203125\n",
            "138 38.41382598876953\n",
            "139 36.332862854003906\n",
            "140 34.370635986328125\n",
            "141 32.517269134521484\n",
            "142 30.76898765563965\n",
            "143 29.116533279418945\n",
            "144 27.55792808532715\n",
            "145 26.08561897277832\n",
            "146 24.694355010986328\n",
            "147 23.379676818847656\n",
            "148 22.13813591003418\n",
            "149 20.965492248535156\n",
            "150 19.85602378845215\n",
            "151 18.808303833007812\n",
            "152 17.817197799682617\n",
            "153 16.880889892578125\n",
            "154 15.995311737060547\n",
            "155 15.15793228149414\n",
            "156 14.366055488586426\n",
            "157 13.616883277893066\n",
            "158 12.908146858215332\n",
            "159 12.237586975097656\n",
            "160 11.603570938110352\n",
            "161 11.00322151184082\n",
            "162 10.4354248046875\n",
            "163 9.897371292114258\n",
            "164 9.388818740844727\n",
            "165 8.9064359664917\n",
            "166 8.450139999389648\n",
            "167 8.018111228942871\n",
            "168 7.608608245849609\n",
            "169 7.221286773681641\n",
            "170 6.853899002075195\n",
            "171 6.506208419799805\n",
            "172 6.1767144203186035\n",
            "173 5.864340305328369\n",
            "174 5.568436622619629\n",
            "175 5.288036346435547\n",
            "176 5.022098541259766\n",
            "177 4.769904136657715\n",
            "178 4.531124114990234\n",
            "179 4.304778575897217\n",
            "180 4.089944839477539\n",
            "181 3.8860511779785156\n",
            "182 3.6927154064178467\n",
            "183 3.5095672607421875\n",
            "184 3.3354227542877197\n",
            "185 3.1705892086029053\n",
            "186 3.0140340328216553\n",
            "187 2.8655760288238525\n",
            "188 2.7244620323181152\n",
            "189 2.5907294750213623\n",
            "190 2.463684558868408\n",
            "191 2.34313702583313\n",
            "192 2.228688955307007\n",
            "193 2.1201112270355225\n",
            "194 2.017040967941284\n",
            "195 1.9189649820327759\n",
            "196 1.8258908987045288\n",
            "197 1.737593650817871\n",
            "198 1.6535447835922241\n",
            "199 1.5737546682357788\n",
            "200 1.497877836227417\n",
            "201 1.4257644414901733\n",
            "202 1.357348084449768\n",
            "203 1.2924302816390991\n",
            "204 1.2306777238845825\n",
            "205 1.1719077825546265\n",
            "206 1.1160553693771362\n",
            "207 1.0629217624664307\n",
            "208 1.0124152898788452\n",
            "209 0.9644915461540222\n",
            "210 0.9188042879104614\n",
            "211 0.8754090666770935\n",
            "212 0.8341062664985657\n",
            "213 0.7947860956192017\n",
            "214 0.757378339767456\n",
            "215 0.7218834161758423\n",
            "216 0.688075602054596\n",
            "217 0.6558401584625244\n",
            "218 0.6252689361572266\n",
            "219 0.5960175395011902\n",
            "220 0.5683121085166931\n",
            "221 0.5418125987052917\n",
            "222 0.5167039632797241\n",
            "223 0.49281758069992065\n",
            "224 0.4699476957321167\n",
            "225 0.4482196867465973\n",
            "226 0.42758142948150635\n",
            "227 0.40780767798423767\n",
            "228 0.38911840319633484\n",
            "229 0.3712697923183441\n",
            "230 0.354256272315979\n",
            "231 0.3380529582500458\n",
            "232 0.32258468866348267\n",
            "233 0.30782800912857056\n",
            "234 0.2938288152217865\n",
            "235 0.28045469522476196\n",
            "236 0.2677578032016754\n",
            "237 0.25562939047813416\n",
            "238 0.24404224753379822\n",
            "239 0.23301008343696594\n",
            "240 0.22251316905021667\n",
            "241 0.21248207986354828\n",
            "242 0.2029309868812561\n",
            "243 0.19378213584423065\n",
            "244 0.18509632349014282\n",
            "245 0.176781564950943\n",
            "246 0.16887733340263367\n",
            "247 0.16132599115371704\n",
            "248 0.1541213095188141\n",
            "249 0.14725880324840546\n",
            "250 0.14069634675979614\n",
            "251 0.1344941109418869\n",
            "252 0.1285015493631363\n",
            "253 0.12282150983810425\n",
            "254 0.11737260967493057\n",
            "255 0.11218206584453583\n",
            "256 0.10722695291042328\n",
            "257 0.10252313315868378\n",
            "258 0.09800814837217331\n",
            "259 0.09369520097970963\n",
            "260 0.08962604403495789\n",
            "261 0.08565357327461243\n",
            "262 0.08191042393445969\n",
            "263 0.0783218964934349\n",
            "264 0.0749213844537735\n",
            "265 0.07165995240211487\n",
            "266 0.06853197515010834\n",
            "267 0.06556118279695511\n",
            "268 0.06274613738059998\n",
            "269 0.05999977886676788\n",
            "270 0.05741201713681221\n",
            "271 0.054932136088609695\n",
            "272 0.05257082358002663\n",
            "273 0.05031776428222656\n",
            "274 0.048139605671167374\n",
            "275 0.04608524590730667\n",
            "276 0.04410548508167267\n",
            "277 0.04222935810685158\n",
            "278 0.04042355716228485\n",
            "279 0.0386926494538784\n",
            "280 0.03704044967889786\n",
            "281 0.03546064347028732\n",
            "282 0.033953797072172165\n",
            "283 0.03250502049922943\n",
            "284 0.03113105520606041\n",
            "285 0.02981664426624775\n",
            "286 0.028558827936649323\n",
            "287 0.027360480278730392\n",
            "288 0.026201019063591957\n",
            "289 0.025094807147979736\n",
            "290 0.024046752601861954\n",
            "291 0.02303367853164673\n",
            "292 0.022077186033129692\n",
            "293 0.021150600165128708\n",
            "294 0.020266614854335785\n",
            "295 0.019426193088293076\n",
            "296 0.018611058592796326\n",
            "297 0.01785062626004219\n",
            "298 0.017108455300331116\n",
            "299 0.016407839953899384\n",
            "300 0.0157299991697073\n",
            "301 0.015083320438861847\n",
            "302 0.014464815147221088\n",
            "303 0.013861974701285362\n",
            "304 0.013300239108502865\n",
            "305 0.012763471342623234\n",
            "306 0.012243134900927544\n",
            "307 0.011749541386961937\n",
            "308 0.011266397312283516\n",
            "309 0.010812455788254738\n",
            "310 0.010376501828432083\n",
            "311 0.009960856288671494\n",
            "312 0.009560356847941875\n",
            "313 0.009170137345790863\n",
            "314 0.008808694779872894\n",
            "315 0.008454280905425549\n",
            "316 0.008118793368339539\n",
            "317 0.007794482633471489\n",
            "318 0.007487921044230461\n",
            "319 0.007187684066593647\n",
            "320 0.006901375949382782\n",
            "321 0.006632736884057522\n",
            "322 0.006374903488904238\n",
            "323 0.006123802158981562\n",
            "324 0.005888651590794325\n",
            "325 0.005660739727318287\n",
            "326 0.005446350667625666\n",
            "327 0.0052328892052173615\n",
            "328 0.005025830585509539\n",
            "329 0.004831657744944096\n",
            "330 0.004644658882170916\n",
            "331 0.0044679478742182255\n",
            "332 0.0042971046641469\n",
            "333 0.004133136477321386\n",
            "334 0.003977714106440544\n",
            "335 0.0038278165739029646\n",
            "336 0.003684458788484335\n",
            "337 0.0035473969765007496\n",
            "338 0.0034140755888074636\n",
            "339 0.0032898574136197567\n",
            "340 0.0031679149251431227\n",
            "341 0.00304879411123693\n",
            "342 0.002935084281489253\n",
            "343 0.0028290809132158756\n",
            "344 0.002723771147429943\n",
            "345 0.002623329870402813\n",
            "346 0.0025318902917206287\n",
            "347 0.002436097478494048\n",
            "348 0.0023511317558586597\n",
            "349 0.0022648824378848076\n",
            "350 0.0021866122260689735\n",
            "351 0.0021068211644887924\n",
            "352 0.0020323770586401224\n",
            "353 0.0019600491505116224\n",
            "354 0.0018923120805993676\n",
            "355 0.0018251631408929825\n",
            "356 0.0017634676769375801\n",
            "357 0.0017036865465342999\n",
            "358 0.0016452072886750102\n",
            "359 0.0015875922981649637\n",
            "360 0.0015339134261012077\n",
            "361 0.0014796849573031068\n",
            "362 0.0014315239386633039\n",
            "363 0.0013828749069944024\n",
            "364 0.0013369454536587\n",
            "365 0.0012926956405863166\n",
            "366 0.001250681933015585\n",
            "367 0.0012088485527783632\n",
            "368 0.0011703247437253594\n",
            "369 0.0011315990705043077\n",
            "370 0.0010963284876197577\n",
            "371 0.0010604908457025886\n",
            "372 0.0010283330921083689\n",
            "373 0.0009953598491847515\n",
            "374 0.000963767699431628\n",
            "375 0.000932463794015348\n",
            "376 0.0009045046172104776\n",
            "377 0.000877134851180017\n",
            "378 0.0008499176474288106\n",
            "379 0.0008233329863287508\n",
            "380 0.0007980092195793986\n",
            "381 0.0007742084562778473\n",
            "382 0.0007493104203604162\n",
            "383 0.0007266938337124884\n",
            "384 0.0007053439621813595\n",
            "385 0.000684786937199533\n",
            "386 0.0006640242063440382\n",
            "387 0.0006444114842452109\n",
            "388 0.000625890155788511\n",
            "389 0.0006074241828173399\n",
            "390 0.0005897730006836355\n",
            "391 0.0005721691413782537\n",
            "392 0.0005564333405345678\n",
            "393 0.0005401982925832272\n",
            "394 0.0005247755325399339\n",
            "395 0.000510983110871166\n",
            "396 0.0004960264777764678\n",
            "397 0.00048262844211421907\n",
            "398 0.00046903459588065743\n",
            "399 0.0004562774847727269\n",
            "400 0.0004435847222339362\n",
            "401 0.0004325133631937206\n",
            "402 0.00042085189488716424\n",
            "403 0.000410329521400854\n",
            "404 0.00039858301170170307\n",
            "405 0.0003880880249198526\n",
            "406 0.0003787554451264441\n",
            "407 0.00036880761035718024\n",
            "408 0.0003581673954613507\n",
            "409 0.00034927541855722666\n",
            "410 0.00034035247517749667\n",
            "411 0.00033204955980181694\n",
            "412 0.0003237562777940184\n",
            "413 0.00031498822499997914\n",
            "414 0.0003078297304455191\n",
            "415 0.00030012454953975976\n",
            "416 0.0002928829344455153\n",
            "417 0.00028616582858376205\n",
            "418 0.00027925442554987967\n",
            "419 0.00027273231535218656\n",
            "420 0.00026613505906425416\n",
            "421 0.0002589935320429504\n",
            "422 0.0002531931095290929\n",
            "423 0.00024738258798606694\n",
            "424 0.00024167619994841516\n",
            "425 0.00023617155966348946\n",
            "426 0.00023087780573405325\n",
            "427 0.0002256411680718884\n",
            "428 0.00021980957535561174\n",
            "429 0.00021439349802676588\n",
            "430 0.00021014249068684876\n",
            "431 0.00020507184672169387\n",
            "432 0.00020072999177500606\n",
            "433 0.00019618167425505817\n",
            "434 0.000192071616766043\n",
            "435 0.00018807982269208878\n",
            "436 0.00018373955390416086\n",
            "437 0.00018011333304457366\n",
            "438 0.00017592671792954206\n",
            "439 0.00017252677935175598\n",
            "440 0.0001688909687800333\n",
            "441 0.00016549423162359744\n",
            "442 0.0001617317902855575\n",
            "443 0.00015873093798290938\n",
            "444 0.00015536558930762112\n",
            "445 0.0001526300038676709\n",
            "446 0.0001493716990808025\n",
            "447 0.00014603826275561005\n",
            "448 0.00014347078104037791\n",
            "449 0.0001407700910931453\n",
            "450 0.00013777597632724792\n",
            "451 0.0001347745710518211\n",
            "452 0.00013245115405879915\n",
            "453 0.00012971468095202\n",
            "454 0.00012735446216538548\n",
            "455 0.00012458441779017448\n",
            "456 0.00012227818660903722\n",
            "457 0.00012017651170026511\n",
            "458 0.0001182482810690999\n",
            "459 0.00011597048433031887\n",
            "460 0.00011374703171895817\n",
            "461 0.00011132389772683382\n",
            "462 0.00010925876267720014\n",
            "463 0.00010745272447820753\n",
            "464 0.00010559568909229711\n",
            "465 0.00010388433292973787\n",
            "466 0.00010192944318987429\n",
            "467 0.00010013658902607858\n",
            "468 9.839859558269382e-05\n",
            "469 9.686136763775721e-05\n",
            "470 9.52863265410997e-05\n",
            "471 9.349161700811237e-05\n",
            "472 9.17674697120674e-05\n",
            "473 9.023297025123611e-05\n",
            "474 8.901165710994974e-05\n",
            "475 8.768695988692343e-05\n",
            "476 8.629666263004765e-05\n",
            "477 8.446068386547267e-05\n",
            "478 8.306359086418524e-05\n",
            "479 8.205755148082972e-05\n",
            "480 8.055055513978004e-05\n",
            "481 7.911526336101815e-05\n",
            "482 7.770280353724957e-05\n",
            "483 7.664189615752548e-05\n",
            "484 7.5345320510678e-05\n",
            "485 7.42390620871447e-05\n",
            "486 7.316861592698842e-05\n",
            "487 7.212166383396834e-05\n",
            "488 7.111427839845419e-05\n",
            "489 6.977125303819776e-05\n",
            "490 6.901657616253942e-05\n",
            "491 6.775659130653366e-05\n",
            "492 6.652269803453237e-05\n",
            "493 6.55873809591867e-05\n",
            "494 6.454372487496585e-05\n",
            "495 6.36925979051739e-05\n",
            "496 6.274688348639756e-05\n",
            "497 6.193131412146613e-05\n",
            "498 6.104136991780251e-05\n",
            "499 6.017859050189145e-05\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycwxAPHZLNST"
      },
      "source": [
        "\n",
        "\n",
        "---\n",
        "## Question 12\n",
        "\n",
        "In the code above, why do we have 2 in '2.0*(y_pred - y)`?\n",
        "\n",
        "## Question 13\n",
        "In the code above, what does `grad_h[h < 0] = 0` signify?\n",
        "\n",
        "## Question 14\n",
        "In the code above, how many \"epochs\" have we trained the model for? \n",
        "\n",
        "## Question 15\n",
        "In the code above, if we take the trained model, and run it on fresh  inputs, the trained model will be able to predict fresh output with high accuracy. \n",
        "\n",
        "## Question 16\n",
        "In the code above, if we dont use clone in `grad_h = grad_h_relu.clone()` the model will still train without any issues. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnJ49I07JJI6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JmHcx2ZWe1im"
      },
      "source": [
        "Q12: To calculate euclidean distance (N = 2)\n",
        "q13 :It replaces with zeros all the values in grad_h where its corresponding h is negative.\n",
        "Q14 : 500\n",
        "Q15:  No gurantee.\n",
        "Q16: Yes, we are cloning to make a copy of the gradient of relu such that it does not share the memory with the original grad_h_relu. "
      ]
    }
  ]
}