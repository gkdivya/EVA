{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "MNIST_Architecture_13k_parameters.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gkdivya/EVA/blob/main/5_CodingDrillDown/Experiments/MNIST_Exp1_BasicSkeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAWtYhLEGJy7"
      },
      "source": [
        "Target:\n",
        "\n",
        "\n",
        "Results:\n",
        "\n",
        "\n",
        "*   Parameters: \n",
        "*   Best Train Accuracy: \n",
        "*   Best Test Accuracy: \n",
        "\n",
        "Analysis:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Ksuetn8Vl4"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "Let's first import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIELYTz8Za0"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "\n",
        "        #Block 1\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3,padding=0,bias=False),  # 28x28 output 28x28 RF : 3x3\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(8, 16, 3,padding=0,bias=False), # 28x28 output 28x28 RF : 5x5\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "        \n",
        "        )\n",
        "\n",
        "        #Transition Block (MaxPool + 1x1)\n",
        "        self.trans1 = nn.Sequential(\n",
        "\n",
        "            # 1x1 convolution\n",
        "            nn.Conv2d(16, 8, 1,bias=False), # 26x26 output - 26x26 RF 14x14\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2, 2),  # 26x26 output - 13x13 RF 14x14\n",
        "\n",
        "        )\n",
        "\n",
        "        #Block 2\n",
        "        self.conv2 =  nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(8, 16, 3,padding=0, bias=False), # 13x13 output - 11x11 RF 16x16\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False),  # 11x11 output - 9x9 RF 18x18\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 10, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.trans1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(-1,10)\n",
        "\n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "4882df66-6f4e-4e54-ffa6-d943cdf68574"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "            Conv2d-3           [-1, 16, 24, 24]           1,152\n",
            "              ReLU-4           [-1, 16, 24, 24]               0\n",
            "            Conv2d-5           [-1, 16, 22, 22]           2,304\n",
            "              ReLU-6           [-1, 16, 22, 22]               0\n",
            "            Conv2d-7            [-1, 8, 22, 22]             128\n",
            "              ReLU-8            [-1, 8, 22, 22]               0\n",
            "         MaxPool2d-9            [-1, 8, 11, 11]               0\n",
            "           Conv2d-10             [-1, 16, 9, 9]           1,152\n",
            "             ReLU-11             [-1, 16, 9, 9]               0\n",
            "           Conv2d-12             [-1, 16, 7, 7]           2,304\n",
            "             ReLU-13             [-1, 16, 7, 7]               0\n",
            "           Conv2d-14             [-1, 16, 5, 5]           2,304\n",
            "             ReLU-15             [-1, 16, 5, 5]               0\n",
            "           Conv2d-16             [-1, 16, 3, 3]           2,304\n",
            "             ReLU-17             [-1, 16, 3, 3]               0\n",
            "           Conv2d-18             [-1, 10, 1, 1]           1,440\n",
            "================================================================\n",
            "Total params: 13,160\n",
            "Trainable params: 13,160\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.50\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIArnZJ-OXQ"
      },
      "source": [
        "## The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuCk_KKM-Foy",
        "outputId": "fde91d60-85bd-48ee-9211-923909d88ada"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (5): ReLU()\n",
              "  )\n",
              "  (trans1): Sequential(\n",
              "    (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (7): ReLU()\n",
              "    (8): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukLGDPFg-LNr"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVv5BP_c-IZ8",
        "outputId": "33a42487-3702-4288-e73e-3a8b77302c81"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,160 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h0khHDE8oz8"
      },
      "source": [
        "## Load and Prepare Dataset\n",
        "\n",
        "MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels\n",
        "\n",
        "We load the PIL images using torchvision.datasets.MNIST, while loading the image we transform he data to tensor and normalize the images with mean and std deviation of MNIST images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]))\n",
        "\n",
        "test = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]))\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, **kwargs)\n"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7uA-_b5-V4d"
      },
      "source": [
        "## Training and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fDefDhaFlwH"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    epoch_loss=0\n",
        "    correct = 0\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        pbar.set_description(desc= f'epoch={epoch} Loss={loss.item()} batch_id={batch_idx:05d}')\n",
        "\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader.dataset)\n",
        "    train_acc=100.*correct/len(train_loader.dataset)\n",
        "    return train_loss,train_acc\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    test_acc=100. * correct / len(test_loader.dataset)\n",
        "    return test_loss,test_acc"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCTPjqWF-hj6"
      },
      "source": [
        "## Let's write train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MMWbLWO6FuHb",
        "outputId": "940808f3-3374-4bb9-ccff-db235e6094ab"
      },
      "source": [
        "\n",
        "model = Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
        "\n",
        "train_loss_values = []\n",
        "test_loss_values = []\n",
        "train_accuracy=[]\n",
        "test_accuracy=[]\n",
        "\n",
        "for epoch in range(1, 15):\n",
        "    train_loss,train_acc = train(model, device, train_loader, optimizer, epoch)\n",
        "    test_loss,test_acc = test(model, device, test_loader)\n",
        "\n",
        "    train_loss_values.append(train_loss)\n",
        "    test_loss_values.append(test_loss)\n",
        "\n",
        "    train_accuracy.append(train_acc)\n",
        "    test_accuracy.append(test_acc)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=1 Loss=2.302581548690796 batch_id=00000:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025848865509033 batch_id=00001:   0%|          | 0/469 [00:00<?, ?it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025848865509033 batch_id=00001:   0%|          | 2/469 [00:00<00:26, 17.89it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025946617126465 batch_id=00002:   0%|          | 2/469 [00:00<00:26, 17.89it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025808334350586 batch_id=00003:   0%|          | 2/469 [00:00<00:26, 17.89it/s]\u001b[A\n",
            "epoch=1 Loss=2.302605628967285 batch_id=00004:   0%|          | 2/469 [00:00<00:26, 17.89it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025527000427246 batch_id=00005:   0%|          | 2/469 [00:00<00:26, 17.89it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025527000427246 batch_id=00005:   1%|▏         | 6/469 [00:00<00:22, 20.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025925159454346 batch_id=00006:   1%|▏         | 6/469 [00:00<00:22, 20.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.302603244781494 batch_id=00007:   1%|▏         | 6/469 [00:00<00:22, 20.63it/s] \u001b[A\n",
            "epoch=1 Loss=2.3026154041290283 batch_id=00008:   1%|▏         | 6/469 [00:00<00:22, 20.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.30264949798584 batch_id=00009:   1%|▏         | 6/469 [00:00<00:22, 20.63it/s]  \u001b[A\n",
            "epoch=1 Loss=2.30264949798584 batch_id=00009:   2%|▏         | 10/469 [00:00<00:19, 23.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025600910186768 batch_id=00010:   2%|▏         | 10/469 [00:00<00:19, 23.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.302563190460205 batch_id=00011:   2%|▏         | 10/469 [00:00<00:19, 23.54it/s] \u001b[A\n",
            "epoch=1 Loss=2.302605390548706 batch_id=00012:   2%|▏         | 10/469 [00:00<00:19, 23.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025941848754883 batch_id=00013:   2%|▏         | 10/469 [00:00<00:19, 23.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025941848754883 batch_id=00013:   3%|▎         | 14/469 [00:00<00:17, 25.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025786876678467 batch_id=00014:   3%|▎         | 14/469 [00:00<00:17, 25.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.302611827850342 batch_id=00015:   3%|▎         | 14/469 [00:00<00:17, 25.99it/s] \u001b[A\n",
            "epoch=1 Loss=2.302576780319214 batch_id=00016:   3%|▎         | 14/469 [00:00<00:17, 25.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025450706481934 batch_id=00017:   3%|▎         | 14/469 [00:00<00:17, 25.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025450706481934 batch_id=00017:   4%|▍         | 18/469 [00:00<00:15, 28.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026111125946045 batch_id=00018:   4%|▍         | 18/469 [00:00<00:15, 28.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025457859039307 batch_id=00019:   4%|▍         | 18/469 [00:00<00:15, 28.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025753498077393 batch_id=00020:   4%|▍         | 18/469 [00:00<00:15, 28.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302549362182617 batch_id=00021:   4%|▍         | 18/469 [00:00<00:15, 28.20it/s] \u001b[A\n",
            "epoch=1 Loss=2.302549362182617 batch_id=00021:   5%|▍         | 22/469 [00:00<00:15, 29.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026108741760254 batch_id=00022:   5%|▍         | 22/469 [00:00<00:15, 29.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025360107421875 batch_id=00023:   5%|▍         | 22/469 [00:00<00:15, 29.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.302588939666748 batch_id=00024:   5%|▍         | 22/469 [00:00<00:15, 29.56it/s] \u001b[A\n",
            "epoch=1 Loss=2.302577018737793 batch_id=00025:   5%|▍         | 22/469 [00:00<00:15, 29.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.302577018737793 batch_id=00025:   6%|▌         | 26/469 [00:00<00:14, 30.35it/s]\u001b[A\n",
            "epoch=1 Loss=2.302572011947632 batch_id=00026:   6%|▌         | 26/469 [00:00<00:14, 30.35it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025619983673096 batch_id=00027:   6%|▌         | 26/469 [00:00<00:14, 30.35it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025941848754883 batch_id=00028:   6%|▌         | 26/469 [00:00<00:14, 30.35it/s]\u001b[A\n",
            "epoch=1 Loss=2.302583932876587 batch_id=00029:   6%|▌         | 26/469 [00:00<00:14, 30.35it/s] \u001b[A\n",
            "epoch=1 Loss=2.302583932876587 batch_id=00029:   6%|▋         | 30/469 [00:00<00:14, 30.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025848865509033 batch_id=00030:   6%|▋         | 30/469 [00:00<00:14, 30.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.302597761154175 batch_id=00031:   6%|▋         | 30/469 [00:01<00:14, 30.90it/s] \u001b[A\n",
            "epoch=1 Loss=2.302589178085327 batch_id=00032:   6%|▋         | 30/469 [00:01<00:14, 30.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.302565336227417 batch_id=00033:   6%|▋         | 30/469 [00:01<00:14, 30.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.302565336227417 batch_id=00033:   7%|▋         | 34/469 [00:01<00:14, 30.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026020526885986 batch_id=00034:   7%|▋         | 34/469 [00:01<00:14, 30.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025591373443604 batch_id=00035:   7%|▋         | 34/469 [00:01<00:14, 30.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025782108306885 batch_id=00036:   7%|▋         | 34/469 [00:01<00:14, 30.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.302604913711548 batch_id=00037:   7%|▋         | 34/469 [00:01<00:14, 30.88it/s] \u001b[A\n",
            "epoch=1 Loss=2.302604913711548 batch_id=00037:   8%|▊         | 38/469 [00:01<00:13, 31.09it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025834560394287 batch_id=00038:   8%|▊         | 38/469 [00:01<00:13, 31.09it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025853633880615 batch_id=00039:   8%|▊         | 38/469 [00:01<00:13, 31.09it/s]\u001b[A\n",
            "epoch=1 Loss=2.302572727203369 batch_id=00040:   8%|▊         | 38/469 [00:01<00:13, 31.09it/s] \u001b[A\n",
            "epoch=1 Loss=2.30259108543396 batch_id=00041:   8%|▊         | 38/469 [00:01<00:13, 31.09it/s] \u001b[A\n",
            "epoch=1 Loss=2.30259108543396 batch_id=00041:   9%|▉         | 42/469 [00:01<00:13, 31.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.302624464035034 batch_id=00042:   9%|▉         | 42/469 [00:01<00:13, 31.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.302572250366211 batch_id=00043:   9%|▉         | 42/469 [00:01<00:13, 31.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025827407836914 batch_id=00044:   9%|▉         | 42/469 [00:01<00:13, 31.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.302590847015381 batch_id=00045:   9%|▉         | 42/469 [00:01<00:13, 31.80it/s] \u001b[A\n",
            "epoch=1 Loss=2.302590847015381 batch_id=00045:  10%|▉         | 46/469 [00:01<00:13, 32.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.302590847015381 batch_id=00046:  10%|▉         | 46/469 [00:01<00:13, 32.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.30257511138916 batch_id=00047:  10%|▉         | 46/469 [00:01<00:13, 32.03it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025591373443604 batch_id=00048:  10%|▉         | 46/469 [00:01<00:13, 32.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.302584648132324 batch_id=00049:  10%|▉         | 46/469 [00:01<00:13, 32.03it/s] \u001b[A\n",
            "epoch=1 Loss=2.302584648132324 batch_id=00049:  11%|█         | 50/469 [00:01<00:12, 32.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.30257511138916 batch_id=00050:  11%|█         | 50/469 [00:01<00:12, 32.99it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025588989257812 batch_id=00051:  11%|█         | 50/469 [00:01<00:12, 32.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025424480438232 batch_id=00052:  11%|█         | 50/469 [00:01<00:12, 32.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025689125061035 batch_id=00053:  11%|█         | 50/469 [00:01<00:12, 32.99it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025689125061035 batch_id=00053:  12%|█▏        | 54/469 [00:01<00:12, 32.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.302600145339966 batch_id=00054:  12%|█▏        | 54/469 [00:01<00:12, 32.93it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025591373443604 batch_id=00055:  12%|█▏        | 54/469 [00:01<00:12, 32.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.302605390548706 batch_id=00056:  12%|█▏        | 54/469 [00:01<00:12, 32.93it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025529384613037 batch_id=00057:  12%|█▏        | 54/469 [00:01<00:12, 32.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025529384613037 batch_id=00057:  12%|█▏        | 58/469 [00:01<00:12, 33.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.302560329437256 batch_id=00058:  12%|█▏        | 58/469 [00:01<00:12, 33.43it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025946617126465 batch_id=00059:  12%|█▏        | 58/469 [00:01<00:12, 33.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025808334350586 batch_id=00060:  12%|█▏        | 58/469 [00:01<00:12, 33.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025906085968018 batch_id=00061:  12%|█▏        | 58/469 [00:01<00:12, 33.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025906085968018 batch_id=00061:  13%|█▎        | 62/469 [00:01<00:12, 32.94it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025436401367188 batch_id=00062:  13%|█▎        | 62/469 [00:01<00:12, 32.94it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025591373443604 batch_id=00063:  13%|█▎        | 62/469 [00:01<00:12, 32.94it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00064:  13%|█▎        | 62/469 [00:02<00:12, 32.94it/s]\u001b[A\n",
            "epoch=1 Loss=2.302539110183716 batch_id=00065:  13%|█▎        | 62/469 [00:02<00:12, 32.94it/s] \u001b[A\n",
            "epoch=1 Loss=2.302539110183716 batch_id=00065:  14%|█▍        | 66/469 [00:02<00:12, 32.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.302534580230713 batch_id=00066:  14%|█▍        | 66/469 [00:02<00:12, 32.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025805950164795 batch_id=00067:  14%|█▍        | 66/469 [00:02<00:12, 32.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025963306427 batch_id=00068:  14%|█▍        | 66/469 [00:02<00:12, 32.63it/s]   \u001b[A\n",
            "epoch=1 Loss=2.3025400638580322 batch_id=00069:  14%|█▍        | 66/469 [00:02<00:12, 32.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025400638580322 batch_id=00069:  15%|█▍        | 70/469 [00:02<00:12, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.302560806274414 batch_id=00070:  15%|█▍        | 70/469 [00:02<00:12, 32.64it/s] \u001b[A\n",
            "epoch=1 Loss=2.302574634552002 batch_id=00071:  15%|█▍        | 70/469 [00:02<00:12, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.302584409713745 batch_id=00072:  15%|█▍        | 70/469 [00:02<00:12, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025879859924316 batch_id=00073:  15%|█▍        | 70/469 [00:02<00:12, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025879859924316 batch_id=00073:  16%|█▌        | 74/469 [00:02<00:12, 32.91it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025062084198 batch_id=00074:  16%|█▌        | 74/469 [00:02<00:12, 32.91it/s]   \u001b[A\n",
            "epoch=1 Loss=2.302562713623047 batch_id=00075:  16%|█▌        | 74/469 [00:02<00:12, 32.91it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025739192962646 batch_id=00076:  16%|█▌        | 74/469 [00:02<00:12, 32.91it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025600910186768 batch_id=00077:  16%|█▌        | 74/469 [00:02<00:12, 32.91it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025600910186768 batch_id=00077:  17%|█▋        | 78/469 [00:02<00:11, 33.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025381565093994 batch_id=00078:  17%|█▋        | 78/469 [00:02<00:11, 33.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025550842285156 batch_id=00079:  17%|█▋        | 78/469 [00:02<00:11, 33.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00080:  17%|█▋        | 78/469 [00:02<00:11, 33.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.302618980407715 batch_id=00081:  17%|█▋        | 78/469 [00:02<00:11, 33.67it/s] \u001b[A\n",
            "epoch=1 Loss=2.302618980407715 batch_id=00081:  17%|█▋        | 82/469 [00:02<00:11, 33.73it/s]\u001b[A\n",
            "epoch=1 Loss=2.302553176879883 batch_id=00082:  17%|█▋        | 82/469 [00:02<00:11, 33.73it/s]\u001b[A\n",
            "epoch=1 Loss=2.302560806274414 batch_id=00083:  17%|█▋        | 82/469 [00:02<00:11, 33.73it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025941848754883 batch_id=00084:  17%|█▋        | 82/469 [00:02<00:11, 33.73it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025403022766113 batch_id=00085:  17%|█▋        | 82/469 [00:02<00:11, 33.73it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025403022766113 batch_id=00085:  18%|█▊        | 86/469 [00:02<00:11, 33.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.302581548690796 batch_id=00086:  18%|█▊        | 86/469 [00:02<00:11, 33.30it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025717735290527 batch_id=00087:  18%|█▊        | 86/469 [00:02<00:11, 33.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.302621841430664 batch_id=00088:  18%|█▊        | 86/469 [00:02<00:11, 33.30it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025054931640625 batch_id=00089:  18%|█▊        | 86/469 [00:02<00:11, 33.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025054931640625 batch_id=00089:  19%|█▉        | 90/469 [00:02<00:11, 32.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.302574634552002 batch_id=00090:  19%|█▉        | 90/469 [00:02<00:11, 32.80it/s] \u001b[A\n",
            "epoch=1 Loss=2.302542209625244 batch_id=00091:  19%|█▉        | 90/469 [00:02<00:11, 32.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025248050689697 batch_id=00092:  19%|█▉        | 90/469 [00:02<00:11, 32.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025410175323486 batch_id=00093:  19%|█▉        | 90/469 [00:02<00:11, 32.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025410175323486 batch_id=00093:  20%|██        | 94/469 [00:02<00:11, 32.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025877475738525 batch_id=00094:  20%|██        | 94/469 [00:02<00:11, 32.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302535057067871 batch_id=00095:  20%|██        | 94/469 [00:02<00:11, 32.59it/s] \u001b[A\n",
            "epoch=1 Loss=2.302591562271118 batch_id=00096:  20%|██        | 94/469 [00:02<00:11, 32.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302561044692993 batch_id=00097:  20%|██        | 94/469 [00:03<00:11, 32.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302561044692993 batch_id=00097:  21%|██        | 98/469 [00:03<00:11, 33.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025896549224854 batch_id=00098:  21%|██        | 98/469 [00:03<00:11, 33.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.302570104598999 batch_id=00099:  21%|██        | 98/469 [00:03<00:11, 33.07it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025455474853516 batch_id=00100:  21%|██        | 98/469 [00:03<00:11, 33.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025970458984375 batch_id=00101:  21%|██        | 98/469 [00:03<00:11, 33.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025970458984375 batch_id=00101:  22%|██▏       | 102/469 [00:03<00:11, 33.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.30256986618042 batch_id=00102:  22%|██▏       | 102/469 [00:03<00:11, 33.20it/s]  \u001b[A\n",
            "epoch=1 Loss=2.302544116973877 batch_id=00103:  22%|██▏       | 102/469 [00:03<00:11, 33.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302556276321411 batch_id=00104:  22%|██▏       | 102/469 [00:03<00:11, 33.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302583932876587 batch_id=00105:  22%|██▏       | 102/469 [00:03<00:11, 33.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302583932876587 batch_id=00105:  23%|██▎       | 106/469 [00:03<00:11, 32.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.30260968208313 batch_id=00106:  23%|██▎       | 106/469 [00:03<00:11, 32.14it/s] \u001b[A\n",
            "epoch=1 Loss=2.302567720413208 batch_id=00107:  23%|██▎       | 106/469 [00:03<00:11, 32.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025529384613037 batch_id=00108:  23%|██▎       | 106/469 [00:03<00:11, 32.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025577068328857 batch_id=00109:  23%|██▎       | 106/469 [00:03<00:11, 32.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025577068328857 batch_id=00109:  23%|██▎       | 110/469 [00:03<00:11, 31.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025646209716797 batch_id=00110:  23%|██▎       | 110/469 [00:03<00:11, 31.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025929927825928 batch_id=00111:  23%|██▎       | 110/469 [00:03<00:11, 31.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025825023651123 batch_id=00112:  23%|██▎       | 110/469 [00:03<00:11, 31.67it/s]\u001b[A\n",
            "epoch=1 Loss=2.302570104598999 batch_id=00113:  23%|██▎       | 110/469 [00:03<00:11, 31.67it/s] \u001b[A\n",
            "epoch=1 Loss=2.302570104598999 batch_id=00113:  24%|██▍       | 114/469 [00:03<00:11, 31.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025283813476562 batch_id=00114:  24%|██▍       | 114/469 [00:03<00:11, 31.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025333881378174 batch_id=00115:  24%|██▍       | 114/469 [00:03<00:11, 31.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026185035705566 batch_id=00116:  24%|██▍       | 114/469 [00:03<00:11, 31.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00117:  24%|██▍       | 114/469 [00:03<00:11, 31.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00117:  25%|██▌       | 118/469 [00:03<00:11, 31.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.302554130554199 batch_id=00118:  25%|██▌       | 118/469 [00:03<00:11, 31.56it/s] \u001b[A\n",
            "epoch=1 Loss=2.302622079849243 batch_id=00119:  25%|██▌       | 118/469 [00:03<00:11, 31.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025386333465576 batch_id=00120:  25%|██▌       | 118/469 [00:03<00:11, 31.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025383949279785 batch_id=00121:  25%|██▌       | 118/469 [00:03<00:11, 31.56it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025383949279785 batch_id=00121:  26%|██▌       | 122/469 [00:03<00:11, 31.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302574634552002 batch_id=00122:  26%|██▌       | 122/469 [00:03<00:11, 31.37it/s] \u001b[A\n",
            "epoch=1 Loss=2.302581310272217 batch_id=00123:  26%|██▌       | 122/469 [00:03<00:11, 31.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025083541870117 batch_id=00124:  26%|██▌       | 122/469 [00:03<00:11, 31.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025479316711426 batch_id=00125:  26%|██▌       | 122/469 [00:03<00:11, 31.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025479316711426 batch_id=00125:  27%|██▋       | 126/469 [00:03<00:10, 31.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025424480438232 batch_id=00126:  27%|██▋       | 126/469 [00:03<00:10, 31.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026115894317627 batch_id=00127:  27%|██▋       | 126/469 [00:03<00:10, 31.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025522232055664 batch_id=00128:  27%|██▋       | 126/469 [00:03<00:10, 31.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.302574396133423 batch_id=00129:  27%|██▋       | 126/469 [00:04<00:10, 31.71it/s] \u001b[A\n",
            "epoch=1 Loss=2.302574396133423 batch_id=00129:  28%|██▊       | 130/469 [00:04<00:10, 32.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.302530527114868 batch_id=00130:  28%|██▊       | 130/469 [00:04<00:10, 32.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025851249694824 batch_id=00131:  28%|██▊       | 130/469 [00:04<00:10, 32.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025286197662354 batch_id=00132:  28%|██▊       | 130/469 [00:04<00:10, 32.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00133:  28%|██▊       | 130/469 [00:04<00:10, 32.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025636672973633 batch_id=00133:  29%|██▊       | 134/469 [00:04<00:10, 31.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.302581787109375 batch_id=00134:  29%|██▊       | 134/469 [00:04<00:10, 31.61it/s] \u001b[A\n",
            "epoch=1 Loss=2.3026132583618164 batch_id=00135:  29%|██▊       | 134/469 [00:04<00:10, 31.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025336265563965 batch_id=00136:  29%|██▊       | 134/469 [00:04<00:10, 31.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025424480438232 batch_id=00137:  29%|██▊       | 134/469 [00:04<00:10, 31.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025424480438232 batch_id=00137:  29%|██▉       | 138/469 [00:04<00:10, 32.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026063442230225 batch_id=00138:  29%|██▉       | 138/469 [00:04<00:10, 32.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025922775268555 batch_id=00139:  29%|██▉       | 138/469 [00:04<00:10, 32.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.302574872970581 batch_id=00140:  29%|██▉       | 138/469 [00:04<00:10, 32.30it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025319576263428 batch_id=00141:  29%|██▉       | 138/469 [00:04<00:10, 32.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025319576263428 batch_id=00141:  30%|███       | 142/469 [00:04<00:10, 32.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025691509246826 batch_id=00142:  30%|███       | 142/469 [00:04<00:10, 32.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025546073913574 batch_id=00143:  30%|███       | 142/469 [00:04<00:10, 32.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.302551746368408 batch_id=00144:  30%|███       | 142/469 [00:04<00:10, 32.07it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025262355804443 batch_id=00145:  30%|███       | 142/469 [00:04<00:10, 32.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025262355804443 batch_id=00145:  31%|███       | 146/469 [00:04<00:09, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025686740875244 batch_id=00146:  31%|███       | 146/469 [00:04<00:09, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025524616241455 batch_id=00147:  31%|███       | 146/469 [00:04<00:09, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025667667388916 batch_id=00148:  31%|███       | 146/469 [00:04<00:09, 32.64it/s]\u001b[A\n",
            "epoch=1 Loss=2.302584171295166 batch_id=00149:  31%|███       | 146/469 [00:04<00:09, 32.64it/s] \u001b[A\n",
            "epoch=1 Loss=2.302584171295166 batch_id=00149:  32%|███▏      | 150/469 [00:04<00:09, 33.28it/s]\u001b[A\n",
            "epoch=1 Loss=2.302565813064575 batch_id=00150:  32%|███▏      | 150/469 [00:04<00:09, 33.28it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025362491607666 batch_id=00151:  32%|███▏      | 150/469 [00:04<00:09, 33.28it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025119304656982 batch_id=00152:  32%|███▏      | 150/469 [00:04<00:09, 33.28it/s]\u001b[A\n",
            "epoch=1 Loss=2.30254864692688 batch_id=00153:  32%|███▏      | 150/469 [00:04<00:09, 33.28it/s]  \u001b[A\n",
            "epoch=1 Loss=2.30254864692688 batch_id=00153:  33%|███▎      | 154/469 [00:04<00:09, 31.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025243282318115 batch_id=00154:  33%|███▎      | 154/469 [00:04<00:09, 31.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025410175323486 batch_id=00155:  33%|███▎      | 154/469 [00:04<00:09, 31.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025400638580322 batch_id=00156:  33%|███▎      | 154/469 [00:04<00:09, 31.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025286197662354 batch_id=00157:  33%|███▎      | 154/469 [00:04<00:09, 31.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025286197662354 batch_id=00157:  34%|███▎      | 158/469 [00:04<00:10, 30.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025505542755127 batch_id=00158:  34%|███▎      | 158/469 [00:04<00:10, 30.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.302497148513794 batch_id=00159:  34%|███▎      | 158/469 [00:04<00:10, 30.65it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025240898132324 batch_id=00160:  34%|███▎      | 158/469 [00:05<00:10, 30.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025155067443848 batch_id=00161:  34%|███▎      | 158/469 [00:05<00:10, 30.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025155067443848 batch_id=00161:  35%|███▍      | 162/469 [00:05<00:10, 30.58it/s]\u001b[A\n",
            "epoch=1 Loss=2.30254864692688 batch_id=00162:  35%|███▍      | 162/469 [00:05<00:10, 30.58it/s]  \u001b[A\n",
            "epoch=1 Loss=2.302539587020874 batch_id=00163:  35%|███▍      | 162/469 [00:05<00:10, 30.58it/s]\u001b[A\n",
            "epoch=1 Loss=2.302593946456909 batch_id=00164:  35%|███▍      | 162/469 [00:05<00:10, 30.58it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024892807006836 batch_id=00165:  35%|███▍      | 162/469 [00:05<00:10, 30.58it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024892807006836 batch_id=00165:  35%|███▌      | 166/469 [00:05<00:10, 29.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025827407836914 batch_id=00166:  35%|███▌      | 166/469 [00:05<00:10, 29.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025693893432617 batch_id=00167:  35%|███▌      | 166/469 [00:05<00:10, 29.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025357723236084 batch_id=00168:  35%|███▌      | 166/469 [00:05<00:10, 29.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025527000427246 batch_id=00169:  35%|███▌      | 166/469 [00:05<00:10, 29.03it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025527000427246 batch_id=00169:  36%|███▌      | 170/469 [00:05<00:10, 29.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025364875793457 batch_id=00170:  36%|███▌      | 170/469 [00:05<00:10, 29.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025147914886475 batch_id=00171:  36%|███▌      | 170/469 [00:05<00:10, 29.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.30253267288208 batch_id=00172:  36%|███▌      | 170/469 [00:05<00:10, 29.69it/s]  \u001b[A\n",
            "epoch=1 Loss=2.30253267288208 batch_id=00172:  37%|███▋      | 173/469 [00:05<00:10, 29.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302555799484253 batch_id=00173:  37%|███▋      | 173/469 [00:05<00:10, 29.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302544116973877 batch_id=00174:  37%|███▋      | 173/469 [00:05<00:10, 29.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025565147399902 batch_id=00175:  37%|███▋      | 173/469 [00:05<00:10, 29.20it/s]\u001b[A\n",
            "epoch=1 Loss=2.302541971206665 batch_id=00176:  37%|███▋      | 173/469 [00:05<00:10, 29.20it/s] \u001b[A\n",
            "epoch=1 Loss=2.302541971206665 batch_id=00176:  38%|███▊      | 177/469 [00:05<00:09, 30.41it/s]\u001b[A\n",
            "epoch=1 Loss=2.3026282787323 batch_id=00177:  38%|███▊      | 177/469 [00:05<00:09, 30.41it/s]  \u001b[A\n",
            "epoch=1 Loss=2.302530527114868 batch_id=00178:  38%|███▊      | 177/469 [00:05<00:09, 30.41it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025319576263428 batch_id=00179:  38%|███▊      | 177/469 [00:05<00:09, 30.41it/s]\u001b[A\n",
            "epoch=1 Loss=2.302551746368408 batch_id=00180:  38%|███▊      | 177/469 [00:05<00:09, 30.41it/s] \u001b[A\n",
            "epoch=1 Loss=2.302551746368408 batch_id=00180:  39%|███▊      | 181/469 [00:05<00:09, 31.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025264739990234 batch_id=00181:  39%|███▊      | 181/469 [00:05<00:09, 31.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025522232055664 batch_id=00182:  39%|███▊      | 181/469 [00:05<00:09, 31.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.302548885345459 batch_id=00183:  39%|███▊      | 181/469 [00:05<00:09, 31.21it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025405406951904 batch_id=00184:  39%|███▊      | 181/469 [00:05<00:09, 31.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025405406951904 batch_id=00184:  39%|███▉      | 185/469 [00:05<00:08, 31.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025712966918945 batch_id=00185:  39%|███▉      | 185/469 [00:05<00:08, 31.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.302544116973877 batch_id=00186:  39%|███▉      | 185/469 [00:05<00:08, 31.66it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024938106536865 batch_id=00187:  39%|███▉      | 185/469 [00:05<00:08, 31.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025429248809814 batch_id=00188:  39%|███▉      | 185/469 [00:05<00:08, 31.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025429248809814 batch_id=00188:  40%|████      | 189/469 [00:05<00:08, 31.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.302535057067871 batch_id=00189:  40%|████      | 189/469 [00:05<00:08, 31.36it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024964332580566 batch_id=00190:  40%|████      | 189/469 [00:05<00:08, 31.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.302546501159668 batch_id=00191:  40%|████      | 189/469 [00:06<00:08, 31.36it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025479316711426 batch_id=00192:  40%|████      | 189/469 [00:06<00:08, 31.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025479316711426 batch_id=00192:  41%|████      | 193/469 [00:06<00:08, 31.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302513837814331 batch_id=00193:  41%|████      | 193/469 [00:06<00:08, 31.59it/s] \u001b[A\n",
            "epoch=1 Loss=2.302466869354248 batch_id=00194:  41%|████      | 193/469 [00:06<00:08, 31.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025197982788086 batch_id=00195:  41%|████      | 193/469 [00:06<00:08, 31.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024964332580566 batch_id=00196:  41%|████      | 193/469 [00:06<00:08, 31.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024964332580566 batch_id=00196:  42%|████▏     | 197/469 [00:06<00:08, 30.55it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025293350219727 batch_id=00197:  42%|████▏     | 197/469 [00:06<00:08, 30.55it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025269508361816 batch_id=00198:  42%|████▏     | 197/469 [00:06<00:08, 30.55it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025035858154297 batch_id=00199:  42%|████▏     | 197/469 [00:06<00:08, 30.55it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024909496307373 batch_id=00200:  42%|████▏     | 197/469 [00:06<00:08, 30.55it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024909496307373 batch_id=00200:  43%|████▎     | 201/469 [00:06<00:09, 29.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025600910186768 batch_id=00201:  43%|████▎     | 201/469 [00:06<00:09, 29.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025712966918945 batch_id=00202:  43%|████▎     | 201/469 [00:06<00:09, 29.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.30251407623291 batch_id=00203:  43%|████▎     | 201/469 [00:06<00:09, 29.68it/s]  \u001b[A\n",
            "epoch=1 Loss=2.30251407623291 batch_id=00203:  43%|████▎     | 204/469 [00:06<00:08, 29.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024682998657227 batch_id=00204:  43%|████▎     | 204/469 [00:06<00:08, 29.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.302530288696289 batch_id=00205:  43%|████▎     | 204/469 [00:06<00:08, 29.65it/s] \u001b[A\n",
            "epoch=1 Loss=2.302549123764038 batch_id=00206:  43%|████▎     | 204/469 [00:06<00:08, 29.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025028705596924 batch_id=00207:  43%|████▎     | 204/469 [00:06<00:08, 29.65it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025028705596924 batch_id=00207:  44%|████▍     | 208/469 [00:06<00:08, 30.22it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025152683258057 batch_id=00208:  44%|████▍     | 208/469 [00:06<00:08, 30.22it/s]\u001b[A\n",
            "epoch=1 Loss=2.302565574645996 batch_id=00209:  44%|████▍     | 208/469 [00:06<00:08, 30.22it/s] \u001b[A\n",
            "epoch=1 Loss=2.302499294281006 batch_id=00210:  44%|████▍     | 208/469 [00:06<00:08, 30.22it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025214672088623 batch_id=00211:  44%|████▍     | 208/469 [00:06<00:08, 30.22it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025214672088623 batch_id=00211:  45%|████▌     | 212/469 [00:06<00:08, 29.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025312423706055 batch_id=00212:  45%|████▌     | 212/469 [00:06<00:08, 29.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.302556037902832 batch_id=00213:  45%|████▌     | 212/469 [00:06<00:08, 29.61it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024871349334717 batch_id=00214:  45%|████▌     | 212/469 [00:06<00:08, 29.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024871349334717 batch_id=00214:  46%|████▌     | 215/469 [00:06<00:08, 29.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025593757629395 batch_id=00215:  46%|████▌     | 215/469 [00:06<00:08, 29.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025121688842773 batch_id=00216:  46%|████▌     | 215/469 [00:06<00:08, 29.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025286197662354 batch_id=00217:  46%|████▌     | 215/469 [00:06<00:08, 29.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025429248809814 batch_id=00218:  46%|████▌     | 215/469 [00:06<00:08, 29.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025429248809814 batch_id=00218:  47%|████▋     | 219/469 [00:06<00:08, 30.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025007247924805 batch_id=00219:  47%|████▋     | 219/469 [00:06<00:08, 30.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025119304656982 batch_id=00220:  47%|████▋     | 219/469 [00:06<00:08, 30.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025288581848145 batch_id=00221:  47%|████▋     | 219/469 [00:07<00:08, 30.36it/s]\u001b[A\n",
            "epoch=1 Loss=2.302525281906128 batch_id=00222:  47%|████▋     | 219/469 [00:07<00:08, 30.36it/s] \u001b[A\n",
            "epoch=1 Loss=2.302525281906128 batch_id=00222:  48%|████▊     | 223/469 [00:07<00:08, 29.01it/s]\u001b[A\n",
            "epoch=1 Loss=2.302536964416504 batch_id=00223:  48%|████▊     | 223/469 [00:07<00:08, 29.01it/s]\u001b[A\n",
            "epoch=1 Loss=2.302457809448242 batch_id=00224:  48%|████▊     | 223/469 [00:07<00:08, 29.01it/s]\u001b[A\n",
            "epoch=1 Loss=2.302476167678833 batch_id=00225:  48%|████▊     | 223/469 [00:07<00:08, 29.01it/s]\u001b[A\n",
            "epoch=1 Loss=2.302476167678833 batch_id=00225:  48%|████▊     | 226/469 [00:07<00:08, 27.46it/s]\u001b[A\n",
            "epoch=1 Loss=2.302513360977173 batch_id=00226:  48%|████▊     | 226/469 [00:07<00:08, 27.46it/s]\u001b[A\n",
            "epoch=1 Loss=2.302523136138916 batch_id=00227:  48%|████▊     | 226/469 [00:07<00:08, 27.46it/s]\u001b[A\n",
            "epoch=1 Loss=2.302508592605591 batch_id=00228:  48%|████▊     | 226/469 [00:07<00:08, 27.46it/s]\u001b[A\n",
            "epoch=1 Loss=2.302508592605591 batch_id=00228:  49%|████▉     | 229/469 [00:07<00:08, 27.47it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024818897247314 batch_id=00229:  49%|████▉     | 229/469 [00:07<00:08, 27.47it/s]\u001b[A\n",
            "epoch=1 Loss=2.302478790283203 batch_id=00230:  49%|████▉     | 229/469 [00:07<00:08, 27.47it/s] \u001b[A\n",
            "epoch=1 Loss=2.302492141723633 batch_id=00231:  49%|████▉     | 229/469 [00:07<00:08, 27.47it/s]\u001b[A\n",
            "epoch=1 Loss=2.302492141723633 batch_id=00231:  49%|████▉     | 232/469 [00:07<00:08, 26.38it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024702072143555 batch_id=00232:  49%|████▉     | 232/469 [00:07<00:08, 26.38it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025407791137695 batch_id=00233:  49%|████▉     | 232/469 [00:07<00:08, 26.38it/s]\u001b[A\n",
            "epoch=1 Loss=2.302489995956421 batch_id=00234:  49%|████▉     | 232/469 [00:07<00:08, 26.38it/s] \u001b[A\n",
            "epoch=1 Loss=2.302489995956421 batch_id=00234:  50%|█████     | 235/469 [00:07<00:08, 26.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025286197662354 batch_id=00235:  50%|█████     | 235/469 [00:07<00:08, 26.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024919033050537 batch_id=00236:  50%|█████     | 235/469 [00:07<00:08, 26.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024327754974365 batch_id=00237:  50%|█████     | 235/469 [00:07<00:08, 26.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302515745162964 batch_id=00238:  50%|█████     | 235/469 [00:07<00:08, 26.37it/s] \u001b[A\n",
            "epoch=1 Loss=2.302515745162964 batch_id=00238:  51%|█████     | 239/469 [00:07<00:08, 27.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025243282318115 batch_id=00239:  51%|█████     | 239/469 [00:07<00:08, 27.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025193214416504 batch_id=00240:  51%|█████     | 239/469 [00:07<00:08, 27.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024778366088867 batch_id=00241:  51%|█████     | 239/469 [00:07<00:08, 27.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024778366088867 batch_id=00241:  52%|█████▏    | 242/469 [00:07<00:08, 26.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024983406066895 batch_id=00242:  52%|█████▏    | 242/469 [00:07<00:08, 26.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.302560329437256 batch_id=00243:  52%|█████▏    | 242/469 [00:07<00:08, 26.88it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024637699127197 batch_id=00244:  52%|█████▏    | 242/469 [00:07<00:08, 26.88it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024637699127197 batch_id=00244:  52%|█████▏    | 245/469 [00:07<00:08, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.302535057067871 batch_id=00245:  52%|█████▏    | 245/469 [00:07<00:08, 27.25it/s] \u001b[A\n",
            "epoch=1 Loss=2.302443742752075 batch_id=00246:  52%|█████▏    | 245/469 [00:07<00:08, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024487495422363 batch_id=00247:  52%|█████▏    | 245/469 [00:08<00:08, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024487495422363 batch_id=00247:  53%|█████▎    | 248/469 [00:08<00:08, 27.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024590015411377 batch_id=00248:  53%|█████▎    | 248/469 [00:08<00:08, 27.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.302494525909424 batch_id=00249:  53%|█████▎    | 248/469 [00:08<00:08, 27.54it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024818897247314 batch_id=00250:  53%|█████▎    | 248/469 [00:08<00:08, 27.54it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024818897247314 batch_id=00250:  54%|█████▎    | 251/469 [00:08<00:07, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024826049804688 batch_id=00251:  54%|█████▎    | 251/469 [00:08<00:07, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025529384613037 batch_id=00252:  54%|█████▎    | 251/469 [00:08<00:07, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025295734405518 batch_id=00253:  54%|█████▎    | 251/469 [00:08<00:07, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025295734405518 batch_id=00253:  54%|█████▍    | 254/469 [00:08<00:07, 27.81it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024821281433105 batch_id=00254:  54%|█████▍    | 254/469 [00:08<00:07, 27.81it/s]\u001b[A\n",
            "epoch=1 Loss=2.302457809448242 batch_id=00255:  54%|█████▍    | 254/469 [00:08<00:07, 27.81it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024604320526123 batch_id=00256:  54%|█████▍    | 254/469 [00:08<00:07, 27.81it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024604320526123 batch_id=00256:  55%|█████▍    | 257/469 [00:08<00:07, 27.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025126457214355 batch_id=00257:  55%|█████▍    | 257/469 [00:08<00:07, 27.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024744987487793 batch_id=00258:  55%|█████▍    | 257/469 [00:08<00:07, 27.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.302497148513794 batch_id=00259:  55%|█████▍    | 257/469 [00:08<00:07, 27.69it/s] \u001b[A\n",
            "epoch=1 Loss=2.302497148513794 batch_id=00259:  55%|█████▌    | 260/469 [00:08<00:07, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025026321411133 batch_id=00260:  55%|█████▌    | 260/469 [00:08<00:07, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024799823760986 batch_id=00261:  55%|█████▌    | 260/469 [00:08<00:07, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.302536964416504 batch_id=00262:  55%|█████▌    | 260/469 [00:08<00:07, 28.06it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024539947509766 batch_id=00263:  55%|█████▌    | 260/469 [00:08<00:07, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024539947509766 batch_id=00263:  56%|█████▋    | 264/469 [00:08<00:07, 29.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024871349334717 batch_id=00264:  56%|█████▋    | 264/469 [00:08<00:07, 29.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.302459239959717 batch_id=00265:  56%|█████▋    | 264/469 [00:08<00:07, 29.26it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025128841400146 batch_id=00266:  56%|█████▋    | 264/469 [00:08<00:07, 29.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025128841400146 batch_id=00266:  57%|█████▋    | 267/469 [00:08<00:07, 28.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.30253005027771 batch_id=00267:  57%|█████▋    | 267/469 [00:08<00:07, 28.59it/s]  \u001b[A\n",
            "epoch=1 Loss=2.302464008331299 batch_id=00268:  57%|█████▋    | 267/469 [00:08<00:07, 28.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302483320236206 batch_id=00269:  57%|█████▋    | 267/469 [00:08<00:07, 28.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302483320236206 batch_id=00269:  58%|█████▊    | 270/469 [00:08<00:06, 28.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025224208831787 batch_id=00270:  58%|█████▊    | 270/469 [00:08<00:06, 28.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024630546569824 batch_id=00271:  58%|█████▊    | 270/469 [00:08<00:06, 28.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025362491607666 batch_id=00272:  58%|█████▊    | 270/469 [00:08<00:06, 28.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024609088897705 batch_id=00273:  58%|█████▊    | 270/469 [00:08<00:06, 28.69it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024609088897705 batch_id=00273:  58%|█████▊    | 274/469 [00:08<00:06, 29.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024964332580566 batch_id=00274:  58%|█████▊    | 274/469 [00:08<00:06, 29.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.302515745162964 batch_id=00275:  58%|█████▊    | 274/469 [00:08<00:06, 29.66it/s] \u001b[A\n",
            "epoch=1 Loss=2.302473545074463 batch_id=00276:  58%|█████▊    | 274/469 [00:09<00:06, 29.66it/s]\u001b[A\n",
            "epoch=1 Loss=2.302473545074463 batch_id=00276:  59%|█████▉    | 277/469 [00:09<00:06, 28.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024306297302246 batch_id=00277:  59%|█████▉    | 277/469 [00:09<00:06, 28.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025333881378174 batch_id=00278:  59%|█████▉    | 277/469 [00:09<00:06, 28.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024652004241943 batch_id=00279:  59%|█████▉    | 277/469 [00:09<00:06, 28.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024652004241943 batch_id=00279:  60%|█████▉    | 280/469 [00:09<00:06, 28.53it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024230003356934 batch_id=00280:  60%|█████▉    | 280/469 [00:09<00:06, 28.53it/s]\u001b[A\n",
            "epoch=1 Loss=2.302442789077759 batch_id=00281:  60%|█████▉    | 280/469 [00:09<00:06, 28.53it/s] \u001b[A\n",
            "epoch=1 Loss=2.302523136138916 batch_id=00282:  60%|█████▉    | 280/469 [00:09<00:06, 28.53it/s]\u001b[A\n",
            "epoch=1 Loss=2.302523136138916 batch_id=00282:  60%|██████    | 283/469 [00:09<00:06, 26.62it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024158477783203 batch_id=00283:  60%|██████    | 283/469 [00:09<00:06, 26.62it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024795055389404 batch_id=00284:  60%|██████    | 283/469 [00:09<00:06, 26.62it/s]\u001b[A\n",
            "epoch=1 Loss=2.302485942840576 batch_id=00285:  60%|██████    | 283/469 [00:09<00:06, 26.62it/s] \u001b[A\n",
            "epoch=1 Loss=2.302485942840576 batch_id=00285:  61%|██████    | 286/469 [00:09<00:07, 25.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025271892547607 batch_id=00286:  61%|██████    | 286/469 [00:09<00:07, 25.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024444580078125 batch_id=00287:  61%|██████    | 286/469 [00:09<00:07, 25.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024938106536865 batch_id=00288:  61%|██████    | 286/469 [00:09<00:07, 25.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024938106536865 batch_id=00288:  62%|██████▏   | 289/469 [00:09<00:06, 26.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.30244779586792 batch_id=00289:  62%|██████▏   | 289/469 [00:09<00:06, 26.32it/s]  \u001b[A\n",
            "epoch=1 Loss=2.3024845123291016 batch_id=00290:  62%|██████▏   | 289/469 [00:09<00:06, 26.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023645877838135 batch_id=00291:  62%|██████▏   | 289/469 [00:09<00:06, 26.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023645877838135 batch_id=00291:  62%|██████▏   | 292/469 [00:09<00:06, 26.39it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024652004241943 batch_id=00292:  62%|██████▏   | 292/469 [00:09<00:06, 26.39it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024332523345947 batch_id=00293:  62%|██████▏   | 292/469 [00:09<00:06, 26.39it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024206161499023 batch_id=00294:  62%|██████▏   | 292/469 [00:09<00:06, 26.39it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024206161499023 batch_id=00294:  63%|██████▎   | 295/469 [00:09<00:06, 27.29it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024253845214844 batch_id=00295:  63%|██████▎   | 295/469 [00:09<00:06, 27.29it/s]\u001b[A\n",
            "epoch=1 Loss=2.302471876144409 batch_id=00296:  63%|██████▎   | 295/469 [00:09<00:06, 27.29it/s] \u001b[A\n",
            "epoch=1 Loss=2.3025054931640625 batch_id=00297:  63%|██████▎   | 295/469 [00:09<00:06, 27.29it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025054931640625 batch_id=00297:  64%|██████▎   | 298/469 [00:09<00:06, 27.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024563789367676 batch_id=00298:  64%|██████▎   | 298/469 [00:09<00:06, 27.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.302469491958618 batch_id=00299:  64%|██████▎   | 298/469 [00:09<00:06, 27.85it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024392127990723 batch_id=00300:  64%|██████▎   | 298/469 [00:09<00:06, 27.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025026321411133 batch_id=00301:  64%|██████▎   | 298/469 [00:09<00:06, 27.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025026321411133 batch_id=00301:  64%|██████▍   | 302/469 [00:09<00:05, 28.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.302434206008911 batch_id=00302:  64%|██████▍   | 302/469 [00:09<00:05, 28.63it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024070262908936 batch_id=00303:  64%|██████▍   | 302/469 [00:10<00:05, 28.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024210929870605 batch_id=00304:  64%|██████▍   | 302/469 [00:10<00:05, 28.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024210929870605 batch_id=00304:  65%|██████▌   | 305/469 [00:10<00:06, 27.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.302372455596924 batch_id=00305:  65%|██████▌   | 305/469 [00:10<00:06, 27.00it/s] \u001b[A\n",
            "epoch=1 Loss=2.302490711212158 batch_id=00306:  65%|██████▌   | 305/469 [00:10<00:06, 27.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024702072143555 batch_id=00307:  65%|██████▌   | 305/469 [00:10<00:06, 27.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024702072143555 batch_id=00307:  66%|██████▌   | 308/469 [00:10<00:06, 26.16it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024024963378906 batch_id=00308:  66%|██████▌   | 308/469 [00:10<00:06, 26.16it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024001121520996 batch_id=00309:  66%|██████▌   | 308/469 [00:10<00:06, 26.16it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024888038635254 batch_id=00310:  66%|██████▌   | 308/469 [00:10<00:06, 26.16it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023767471313477 batch_id=00311:  66%|██████▌   | 308/469 [00:10<00:06, 26.16it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023767471313477 batch_id=00311:  67%|██████▋   | 312/469 [00:10<00:05, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.302459955215454 batch_id=00312:  67%|██████▋   | 312/469 [00:10<00:05, 27.21it/s] \u001b[A\n",
            "epoch=1 Loss=2.302396059036255 batch_id=00313:  67%|██████▋   | 312/469 [00:10<00:05, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.302432060241699 batch_id=00314:  67%|██████▋   | 312/469 [00:10<00:05, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.302432060241699 batch_id=00314:  67%|██████▋   | 315/469 [00:10<00:05, 27.08it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024606704711914 batch_id=00315:  67%|██████▋   | 315/469 [00:10<00:05, 27.08it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024232387542725 batch_id=00316:  67%|██████▋   | 315/469 [00:10<00:05, 27.08it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024954795837402 batch_id=00317:  67%|██████▋   | 315/469 [00:10<00:05, 27.08it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024954795837402 batch_id=00317:  68%|██████▊   | 318/469 [00:10<00:05, 25.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024747371673584 batch_id=00318:  68%|██████▊   | 318/469 [00:10<00:05, 25.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023524284362793 batch_id=00319:  68%|██████▊   | 318/469 [00:10<00:05, 25.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024373054504395 batch_id=00320:  68%|██████▊   | 318/469 [00:10<00:05, 25.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.302307605743408 batch_id=00321:  68%|██████▊   | 318/469 [00:10<00:05, 25.42it/s] \u001b[A\n",
            "epoch=1 Loss=2.302307605743408 batch_id=00321:  69%|██████▊   | 322/469 [00:10<00:05, 26.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.302433729171753 batch_id=00322:  69%|██████▊   | 322/469 [00:10<00:05, 26.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024115562438965 batch_id=00323:  69%|██████▊   | 322/469 [00:10<00:05, 26.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.302445650100708 batch_id=00324:  69%|██████▊   | 322/469 [00:10<00:05, 26.15it/s] \u001b[A\n",
            "epoch=1 Loss=2.302445650100708 batch_id=00324:  69%|██████▉   | 325/469 [00:10<00:05, 27.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.302480697631836 batch_id=00325:  69%|██████▉   | 325/469 [00:10<00:05, 27.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.302403211593628 batch_id=00326:  69%|██████▉   | 325/469 [00:10<00:05, 27.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024299144744873 batch_id=00327:  69%|██████▉   | 325/469 [00:10<00:05, 27.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023428916931152 batch_id=00328:  69%|██████▉   | 325/469 [00:10<00:05, 27.19it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023428916931152 batch_id=00328:  70%|███████   | 329/469 [00:10<00:05, 27.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.302370548248291 batch_id=00329:  70%|███████   | 329/469 [00:10<00:05, 27.93it/s] \u001b[A\n",
            "epoch=1 Loss=2.302419424057007 batch_id=00330:  70%|███████   | 329/469 [00:11<00:05, 27.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024067878723145 batch_id=00331:  70%|███████   | 329/469 [00:11<00:05, 27.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024067878723145 batch_id=00331:  71%|███████   | 332/469 [00:11<00:04, 27.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.302375316619873 batch_id=00332:  71%|███████   | 332/469 [00:11<00:04, 27.90it/s] \u001b[A\n",
            "epoch=1 Loss=2.30232834815979 batch_id=00333:  71%|███████   | 332/469 [00:11<00:04, 27.90it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024332523345947 batch_id=00334:  71%|███████   | 332/469 [00:11<00:04, 27.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024332523345947 batch_id=00334:  71%|███████▏  | 335/469 [00:11<00:04, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023531436920166 batch_id=00335:  71%|███████▏  | 335/469 [00:11<00:04, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.302436590194702 batch_id=00336:  71%|███████▏  | 335/469 [00:11<00:04, 27.21it/s] \u001b[A\n",
            "epoch=1 Loss=2.3023762702941895 batch_id=00337:  71%|███████▏  | 335/469 [00:11<00:04, 27.21it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023762702941895 batch_id=00337:  72%|███████▏  | 338/469 [00:11<00:04, 26.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3025224208831787 batch_id=00338:  72%|███████▏  | 338/469 [00:11<00:04, 26.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024022579193115 batch_id=00339:  72%|███████▏  | 338/469 [00:11<00:04, 26.63it/s]\u001b[A\n",
            "epoch=1 Loss=2.302377223968506 batch_id=00340:  72%|███████▏  | 338/469 [00:11<00:04, 26.63it/s] \u001b[A\n",
            "epoch=1 Loss=2.302377223968506 batch_id=00340:  73%|███████▎  | 341/469 [00:11<00:04, 26.84it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024685382843018 batch_id=00341:  73%|███████▎  | 341/469 [00:11<00:04, 26.84it/s]\u001b[A\n",
            "epoch=1 Loss=2.302328109741211 batch_id=00342:  73%|███████▎  | 341/469 [00:11<00:04, 26.84it/s] \u001b[A\n",
            "epoch=1 Loss=2.302370071411133 batch_id=00343:  73%|███████▎  | 341/469 [00:11<00:04, 26.84it/s]\u001b[A\n",
            "epoch=1 Loss=2.302370071411133 batch_id=00343:  73%|███████▎  | 344/469 [00:11<00:04, 27.57it/s]\u001b[A\n",
            "epoch=1 Loss=2.302340269088745 batch_id=00344:  73%|███████▎  | 344/469 [00:11<00:04, 27.57it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023951053619385 batch_id=00345:  73%|███████▎  | 344/469 [00:11<00:04, 27.57it/s]\u001b[A\n",
            "epoch=1 Loss=2.302309036254883 batch_id=00346:  73%|███████▎  | 344/469 [00:11<00:04, 27.57it/s] \u001b[A\n",
            "epoch=1 Loss=2.302309036254883 batch_id=00346:  74%|███████▍  | 347/469 [00:11<00:04, 27.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023934364318848 batch_id=00347:  74%|███████▍  | 347/469 [00:11<00:04, 27.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023574352264404 batch_id=00348:  74%|███████▍  | 347/469 [00:11<00:04, 27.90it/s]\u001b[A\n",
            "epoch=1 Loss=2.302485704421997 batch_id=00349:  74%|███████▍  | 347/469 [00:11<00:04, 27.90it/s] \u001b[A\n",
            "epoch=1 Loss=2.302485704421997 batch_id=00349:  75%|███████▍  | 350/469 [00:11<00:04, 27.50it/s]\u001b[A\n",
            "epoch=1 Loss=2.302422046661377 batch_id=00350:  75%|███████▍  | 350/469 [00:11<00:04, 27.50it/s]\u001b[A\n",
            "epoch=1 Loss=2.302330732345581 batch_id=00351:  75%|███████▍  | 350/469 [00:11<00:04, 27.50it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023152351379395 batch_id=00352:  75%|███████▍  | 350/469 [00:11<00:04, 27.50it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023152351379395 batch_id=00352:  75%|███████▌  | 353/469 [00:11<00:04, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.302391529083252 batch_id=00353:  75%|███████▌  | 353/469 [00:11<00:04, 27.71it/s] \u001b[A\n",
            "epoch=1 Loss=2.3024184703826904 batch_id=00354:  75%|███████▌  | 353/469 [00:11<00:04, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024163246154785 batch_id=00355:  75%|███████▌  | 353/469 [00:11<00:04, 27.71it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024163246154785 batch_id=00355:  76%|███████▌  | 356/469 [00:11<00:04, 26.86it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023416996002197 batch_id=00356:  76%|███████▌  | 356/469 [00:11<00:04, 26.86it/s]\u001b[A\n",
            "epoch=1 Loss=2.302319049835205 batch_id=00357:  76%|███████▌  | 356/469 [00:11<00:04, 26.86it/s] \u001b[A\n",
            "epoch=1 Loss=2.3023314476013184 batch_id=00358:  76%|███████▌  | 356/469 [00:12<00:04, 26.86it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023314476013184 batch_id=00358:  77%|███████▋  | 359/469 [00:12<00:04, 26.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.30230975151062 batch_id=00359:  77%|███████▋  | 359/469 [00:12<00:04, 26.61it/s]  \u001b[A\n",
            "epoch=1 Loss=2.3023414611816406 batch_id=00360:  77%|███████▋  | 359/469 [00:12<00:04, 26.61it/s]\u001b[A\n",
            "epoch=1 Loss=2.302318572998047 batch_id=00361:  77%|███████▋  | 359/469 [00:12<00:04, 26.61it/s] \u001b[A\n",
            "epoch=1 Loss=2.302318572998047 batch_id=00361:  77%|███████▋  | 362/469 [00:12<00:03, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022375106811523 batch_id=00362:  77%|███████▋  | 362/469 [00:12<00:03, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.302335500717163 batch_id=00363:  77%|███████▋  | 362/469 [00:12<00:03, 27.32it/s] \u001b[A\n",
            "epoch=1 Loss=2.302400588989258 batch_id=00364:  77%|███████▋  | 362/469 [00:12<00:03, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.302400588989258 batch_id=00364:  78%|███████▊  | 365/469 [00:12<00:03, 26.77it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023300170898438 batch_id=00365:  78%|███████▊  | 365/469 [00:12<00:03, 26.77it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022286891937256 batch_id=00366:  78%|███████▊  | 365/469 [00:12<00:03, 26.77it/s]\u001b[A\n",
            "epoch=1 Loss=2.302347421646118 batch_id=00367:  78%|███████▊  | 365/469 [00:12<00:03, 26.77it/s] \u001b[A\n",
            "epoch=1 Loss=2.302347421646118 batch_id=00367:  78%|███████▊  | 368/469 [00:12<00:03, 27.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023195266723633 batch_id=00368:  78%|███████▊  | 368/469 [00:12<00:03, 27.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3023312091827393 batch_id=00369:  78%|███████▊  | 368/469 [00:12<00:03, 27.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022403717041016 batch_id=00370:  78%|███████▊  | 368/469 [00:12<00:03, 27.30it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022403717041016 batch_id=00370:  79%|███████▉  | 371/469 [00:12<00:03, 27.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.302253246307373 batch_id=00371:  79%|███████▉  | 371/469 [00:12<00:03, 27.14it/s] \u001b[A\n",
            "epoch=1 Loss=2.3023293018341064 batch_id=00372:  79%|███████▉  | 371/469 [00:12<00:03, 27.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.302340507507324 batch_id=00373:  79%|███████▉  | 371/469 [00:12<00:03, 27.14it/s] \u001b[A\n",
            "epoch=1 Loss=2.302340507507324 batch_id=00373:  80%|███████▉  | 374/469 [00:12<00:03, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302194118499756 batch_id=00374:  80%|███████▉  | 374/469 [00:12<00:03, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302457332611084 batch_id=00375:  80%|███████▉  | 374/469 [00:12<00:03, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302238941192627 batch_id=00376:  80%|███████▉  | 374/469 [00:12<00:03, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302236318588257 batch_id=00377:  80%|███████▉  | 374/469 [00:12<00:03, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.302236318588257 batch_id=00377:  81%|████████  | 378/469 [00:12<00:03, 28.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.302330255508423 batch_id=00378:  81%|████████  | 378/469 [00:12<00:03, 28.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022501468658447 batch_id=00379:  81%|████████  | 378/469 [00:12<00:03, 28.43it/s]\u001b[A\n",
            "epoch=1 Loss=2.302250862121582 batch_id=00380:  81%|████████  | 378/469 [00:12<00:03, 28.43it/s] \u001b[A\n",
            "epoch=1 Loss=2.302250862121582 batch_id=00380:  81%|████████  | 381/469 [00:12<00:03, 27.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.302154302597046 batch_id=00381:  81%|████████  | 381/469 [00:12<00:03, 27.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.302403211593628 batch_id=00382:  81%|████████  | 381/469 [00:12<00:03, 27.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022713661193848 batch_id=00383:  81%|████████  | 381/469 [00:12<00:03, 27.95it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022713661193848 batch_id=00383:  82%|████████▏ | 384/469 [00:12<00:03, 28.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022756576538086 batch_id=00384:  82%|████████▏ | 384/469 [00:12<00:03, 28.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.302185535430908 batch_id=00385:  82%|████████▏ | 384/469 [00:13<00:03, 28.14it/s] \u001b[A\n",
            "epoch=1 Loss=2.3021621704101562 batch_id=00386:  82%|████████▏ | 384/469 [00:13<00:03, 28.14it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021621704101562 batch_id=00386:  83%|████████▎ | 387/469 [00:13<00:03, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022398948669434 batch_id=00387:  83%|████████▎ | 387/469 [00:13<00:03, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.30245304107666 batch_id=00388:  83%|████████▎ | 387/469 [00:13<00:03, 27.25it/s]  \u001b[A\n",
            "epoch=1 Loss=2.3022401332855225 batch_id=00389:  83%|████████▎ | 387/469 [00:13<00:03, 27.25it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022401332855225 batch_id=00389:  83%|████████▎ | 390/469 [00:13<00:02, 27.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.302067518234253 batch_id=00390:  83%|████████▎ | 390/469 [00:13<00:02, 27.93it/s] \u001b[A\n",
            "epoch=1 Loss=2.302227735519409 batch_id=00391:  83%|████████▎ | 390/469 [00:13<00:02, 27.93it/s]\u001b[A\n",
            "epoch=1 Loss=2.30226993560791 batch_id=00392:  83%|████████▎ | 390/469 [00:13<00:02, 27.93it/s] \u001b[A\n",
            "epoch=1 Loss=2.30226993560791 batch_id=00392:  84%|████████▍ | 393/469 [00:13<00:02, 27.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.302124500274658 batch_id=00393:  84%|████████▍ | 393/469 [00:13<00:02, 27.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022913932800293 batch_id=00394:  84%|████████▍ | 393/469 [00:13<00:02, 27.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024415969848633 batch_id=00395:  84%|████████▍ | 393/469 [00:13<00:02, 27.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3024415969848633 batch_id=00395:  84%|████████▍ | 396/469 [00:13<00:02, 27.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.302232503890991 batch_id=00396:  84%|████████▍ | 396/469 [00:13<00:02, 27.74it/s] \u001b[A\n",
            "epoch=1 Loss=2.3022220134735107 batch_id=00397:  84%|████████▍ | 396/469 [00:13<00:02, 27.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.302048444747925 batch_id=00398:  84%|████████▍ | 396/469 [00:13<00:02, 27.74it/s] \u001b[A\n",
            "epoch=1 Loss=2.302048444747925 batch_id=00398:  85%|████████▌ | 399/469 [00:13<00:02, 28.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.302252769470215 batch_id=00399:  85%|████████▌ | 399/469 [00:13<00:02, 28.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020739555358887 batch_id=00400:  85%|████████▌ | 399/469 [00:13<00:02, 28.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021435737609863 batch_id=00401:  85%|████████▌ | 399/469 [00:13<00:02, 28.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021435737609863 batch_id=00401:  86%|████████▌ | 402/469 [00:13<00:02, 27.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021342754364014 batch_id=00402:  86%|████████▌ | 402/469 [00:13<00:02, 27.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021745681762695 batch_id=00403:  86%|████████▌ | 402/469 [00:13<00:02, 27.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021035194396973 batch_id=00404:  86%|████████▌ | 402/469 [00:13<00:02, 27.15it/s]\u001b[A\n",
            "epoch=1 Loss=2.302147388458252 batch_id=00405:  86%|████████▌ | 402/469 [00:13<00:02, 27.15it/s] \u001b[A\n",
            "epoch=1 Loss=2.302147388458252 batch_id=00405:  87%|████████▋ | 406/469 [00:13<00:02, 28.12it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022100925445557 batch_id=00406:  87%|████████▋ | 406/469 [00:13<00:02, 28.12it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022377490997314 batch_id=00407:  87%|████████▋ | 406/469 [00:13<00:02, 28.12it/s]\u001b[A\n",
            "epoch=1 Loss=2.302314043045044 batch_id=00408:  87%|████████▋ | 406/469 [00:13<00:02, 28.12it/s] \u001b[A\n",
            "epoch=1 Loss=2.302314043045044 batch_id=00408:  87%|████████▋ | 409/469 [00:13<00:02, 28.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.302037239074707 batch_id=00409:  87%|████████▋ | 409/469 [00:13<00:02, 28.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.302194833755493 batch_id=00410:  87%|████████▋ | 409/469 [00:13<00:02, 28.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019983768463135 batch_id=00411:  87%|████████▋ | 409/469 [00:13<00:02, 28.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019983768463135 batch_id=00411:  88%|████████▊ | 412/469 [00:13<00:02, 28.49it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019726276397705 batch_id=00412:  88%|████████▊ | 412/469 [00:13<00:02, 28.49it/s]\u001b[A\n",
            "epoch=1 Loss=2.30199933052063 batch_id=00413:  88%|████████▊ | 412/469 [00:14<00:02, 28.49it/s]  \u001b[A\n",
            "epoch=1 Loss=2.3022942543029785 batch_id=00414:  88%|████████▊ | 412/469 [00:14<00:02, 28.49it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022942543029785 batch_id=00414:  88%|████████▊ | 415/469 [00:14<00:01, 28.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3022255897521973 batch_id=00415:  88%|████████▊ | 415/469 [00:14<00:01, 28.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020036220550537 batch_id=00416:  88%|████████▊ | 415/469 [00:14<00:01, 28.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020434379577637 batch_id=00417:  88%|████████▊ | 415/469 [00:14<00:01, 28.07it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020434379577637 batch_id=00417:  89%|████████▉ | 418/469 [00:14<00:01, 28.10it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019602298736572 batch_id=00418:  89%|████████▉ | 418/469 [00:14<00:01, 28.10it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021388053894043 batch_id=00419:  89%|████████▉ | 418/469 [00:14<00:01, 28.10it/s]\u001b[A\n",
            "epoch=1 Loss=2.302180767059326 batch_id=00420:  89%|████████▉ | 418/469 [00:14<00:01, 28.10it/s] \u001b[A\n",
            "epoch=1 Loss=2.302180767059326 batch_id=00420:  90%|████████▉ | 421/469 [00:14<00:01, 27.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.3021931648254395 batch_id=00421:  90%|████████▉ | 421/469 [00:14<00:01, 27.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.302168369293213 batch_id=00422:  90%|████████▉ | 421/469 [00:14<00:01, 27.42it/s] \u001b[A\n",
            "epoch=1 Loss=2.3019609451293945 batch_id=00423:  90%|████████▉ | 421/469 [00:14<00:01, 27.42it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019609451293945 batch_id=00423:  90%|█████████ | 424/469 [00:14<00:01, 27.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.30181884765625 batch_id=00424:  90%|█████████ | 424/469 [00:14<00:01, 27.26it/s]  \u001b[A\n",
            "epoch=1 Loss=2.302022695541382 batch_id=00425:  90%|█████████ | 424/469 [00:14<00:01, 27.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.302022933959961 batch_id=00426:  90%|█████████ | 424/469 [00:14<00:01, 27.26it/s]\u001b[A\n",
            "epoch=1 Loss=2.302022933959961 batch_id=00426:  91%|█████████ | 427/469 [00:14<00:01, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020005226135254 batch_id=00427:  91%|█████████ | 427/469 [00:14<00:01, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019909858703613 batch_id=00428:  91%|█████████ | 427/469 [00:14<00:01, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019638061523438 batch_id=00429:  91%|█████████ | 427/469 [00:14<00:01, 27.32it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019638061523438 batch_id=00429:  92%|█████████▏| 430/469 [00:14<00:01, 26.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3018922805786133 batch_id=00430:  92%|█████████▏| 430/469 [00:14<00:01, 26.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.3017995357513428 batch_id=00431:  92%|█████████▏| 430/469 [00:14<00:01, 26.85it/s]\u001b[A\n",
            "epoch=1 Loss=2.301940679550171 batch_id=00432:  92%|█████████▏| 430/469 [00:14<00:01, 26.85it/s] \u001b[A\n",
            "epoch=1 Loss=2.301940679550171 batch_id=00432:  92%|█████████▏| 433/469 [00:14<00:01, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.30204176902771 batch_id=00433:  92%|█████████▏| 433/469 [00:14<00:01, 26.74it/s] \u001b[A\n",
            "epoch=1 Loss=2.301812171936035 batch_id=00434:  92%|█████████▏| 433/469 [00:14<00:01, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.301896095275879 batch_id=00435:  92%|█████████▏| 433/469 [00:14<00:01, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.301896095275879 batch_id=00435:  93%|█████████▎| 436/469 [00:14<00:01, 27.34it/s]\u001b[A\n",
            "epoch=1 Loss=2.301989793777466 batch_id=00436:  93%|█████████▎| 436/469 [00:14<00:01, 27.34it/s]\u001b[A\n",
            "epoch=1 Loss=2.301844596862793 batch_id=00437:  93%|█████████▎| 436/469 [00:14<00:01, 27.34it/s]\u001b[A\n",
            "epoch=1 Loss=2.301866292953491 batch_id=00438:  93%|█████████▎| 436/469 [00:14<00:01, 27.34it/s]\u001b[A\n",
            "epoch=1 Loss=2.301866292953491 batch_id=00438:  94%|█████████▎| 439/469 [00:14<00:01, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.301997661590576 batch_id=00439:  94%|█████████▎| 439/469 [00:14<00:01, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.301731824874878 batch_id=00440:  94%|█████████▎| 439/469 [00:15<00:01, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.301881790161133 batch_id=00441:  94%|█████████▎| 439/469 [00:15<00:01, 27.37it/s]\u001b[A\n",
            "epoch=1 Loss=2.301881790161133 batch_id=00441:  94%|█████████▍| 442/469 [00:15<00:01, 26.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.301845073699951 batch_id=00442:  94%|█████████▍| 442/469 [00:15<00:01, 26.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.301797389984131 batch_id=00443:  94%|█████████▍| 442/469 [00:15<00:01, 26.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3018527030944824 batch_id=00444:  94%|█████████▍| 442/469 [00:15<00:01, 26.59it/s]\u001b[A\n",
            "epoch=1 Loss=2.3018527030944824 batch_id=00444:  95%|█████████▍| 445/469 [00:15<00:00, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.3016903400421143 batch_id=00445:  95%|█████████▍| 445/469 [00:15<00:00, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.301654815673828 batch_id=00446:  95%|█████████▍| 445/469 [00:15<00:00, 26.74it/s] \u001b[A\n",
            "epoch=1 Loss=2.301701784133911 batch_id=00447:  95%|█████████▍| 445/469 [00:15<00:00, 26.74it/s]\u001b[A\n",
            "epoch=1 Loss=2.301701784133911 batch_id=00447:  96%|█████████▌| 448/469 [00:15<00:00, 26.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3020496368408203 batch_id=00448:  96%|█████████▌| 448/469 [00:15<00:00, 26.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.301687717437744 batch_id=00449:  96%|█████████▌| 448/469 [00:15<00:00, 26.68it/s] \u001b[A\n",
            "epoch=1 Loss=2.3017711639404297 batch_id=00450:  96%|█████████▌| 448/469 [00:15<00:00, 26.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3018455505371094 batch_id=00451:  96%|█████████▌| 448/469 [00:15<00:00, 26.68it/s]\u001b[A\n",
            "epoch=1 Loss=2.3018455505371094 batch_id=00451:  96%|█████████▋| 452/469 [00:15<00:00, 28.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.3019073009490967 batch_id=00452:  96%|█████████▋| 452/469 [00:15<00:00, 28.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.301421642303467 batch_id=00453:  96%|█████████▋| 452/469 [00:15<00:00, 28.00it/s] \u001b[A\n",
            "epoch=1 Loss=2.301654577255249 batch_id=00454:  96%|█████████▋| 452/469 [00:15<00:00, 28.00it/s]\u001b[A\n",
            "epoch=1 Loss=2.301654577255249 batch_id=00454:  97%|█████████▋| 455/469 [00:15<00:00, 27.31it/s]\u001b[A\n",
            "epoch=1 Loss=2.30155348777771 batch_id=00455:  97%|█████████▋| 455/469 [00:15<00:00, 27.31it/s] \u001b[A\n",
            "epoch=1 Loss=2.302278757095337 batch_id=00456:  97%|█████████▋| 455/469 [00:15<00:00, 27.31it/s]\u001b[A\n",
            "epoch=1 Loss=2.30134916305542 batch_id=00457:  97%|█████████▋| 455/469 [00:15<00:00, 27.31it/s] \u001b[A\n",
            "epoch=1 Loss=2.30134916305542 batch_id=00457:  98%|█████████▊| 458/469 [00:15<00:00, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.301753520965576 batch_id=00458:  98%|█████████▊| 458/469 [00:15<00:00, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.301994562149048 batch_id=00459:  98%|█████████▊| 458/469 [00:15<00:00, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.3015310764312744 batch_id=00460:  98%|█████████▊| 458/469 [00:15<00:00, 28.06it/s]\u001b[A\n",
            "epoch=1 Loss=2.3015310764312744 batch_id=00460:  98%|█████████▊| 461/469 [00:15<00:00, 27.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3014843463897705 batch_id=00461:  98%|█████████▊| 461/469 [00:15<00:00, 27.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.301664113998413 batch_id=00462:  98%|█████████▊| 461/469 [00:15<00:00, 27.80it/s] \u001b[A\n",
            "epoch=1 Loss=2.301781177520752 batch_id=00463:  98%|█████████▊| 461/469 [00:15<00:00, 27.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3016951084136963 batch_id=00464:  98%|█████████▊| 461/469 [00:15<00:00, 27.80it/s]\u001b[A\n",
            "epoch=1 Loss=2.3016951084136963 batch_id=00464:  99%|█████████▉| 465/469 [00:15<00:00, 29.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.301792621612549 batch_id=00465:  99%|█████████▉| 465/469 [00:15<00:00, 29.13it/s] \u001b[A\n",
            "epoch=1 Loss=2.3017165660858154 batch_id=00466:  99%|█████████▉| 465/469 [00:15<00:00, 29.13it/s]\u001b[A\n",
            "epoch=1 Loss=2.301403760910034 batch_id=00467:  99%|█████████▉| 465/469 [00:15<00:00, 29.13it/s] \u001b[A\n",
            "epoch=1 Loss=2.301403760910034 batch_id=00467: 100%|█████████▉| 468/469 [00:15<00:00, 27.11it/s]\u001b[A\n",
            "epoch=1 Loss=2.3013899326324463 batch_id=00468: 100%|██████████| 469/469 [00:16<00:00, 29.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huAgWlxP8TXR"
      },
      "source": [
        "## Observation:\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}