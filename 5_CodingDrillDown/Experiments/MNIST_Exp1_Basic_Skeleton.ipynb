{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": " MNIST_Exp1_Basic Skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAWtYhLEGJy7"
      },
      "source": [
        "Target:\n",
        "\n",
        "Creation of MNIST Basic Neural Network model without adding any regularization methods.\n",
        "\n",
        "Results:\n",
        "Basic model is overfitted and hence we will have to apply regularization and model opimization methods to improve the test accuracy.\n",
        "\n",
        "\n",
        "*   Parameters: 13,160\n",
        "*   Best Train Accuracy: 99.27%\n",
        "*   Best Test Accuracy: 98.55%\n",
        "\n",
        "Analysis:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G_lUrUJvUXhy"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n7Ksuetn8Vl4"
      },
      "source": [
        "# Import Libraries\n",
        "\n",
        "Let's first import all the necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m2JWFliFfKT"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "# Let's visualize some of the images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hRIELYTz8Za0"
      },
      "source": [
        "## Defining the Model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_Cx9q2QFgM7"
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "\n",
        "        #Block 1\n",
        "        self.conv1 = nn.Sequential(\n",
        "            nn.Conv2d(1, 8, 3,padding=0,bias=False),  # 28x28 output 28x28 RF : 3x3\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(8, 16, 3,padding=0,bias=False), # 28x28 output 28x28 RF : 5x5\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "        \n",
        "        )\n",
        "\n",
        "        #Transition Block (MaxPool + 1x1)\n",
        "        self.trans1 = nn.Sequential(\n",
        "\n",
        "            # 1x1 convolution\n",
        "            nn.Conv2d(16, 8, 1,bias=False), # 26x26 output - 26x26 RF 14x14\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.MaxPool2d(2, 2),  # 26x26 output - 13x13 RF 14x14\n",
        "\n",
        "        )\n",
        "\n",
        "        #Block 2\n",
        "        self.conv2 =  nn.Sequential(\n",
        "\n",
        "            nn.Conv2d(8, 16, 3,padding=0, bias=False), # 13x13 output - 11x11 RF 16x16\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False),  # 11x11 output - 9x9 RF 18x18\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 16, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "            nn.ReLU(),\n",
        "\n",
        "            nn.Conv2d(16, 10, 3,padding=0, bias=False), # 9x9 output - 7x7 RF 20x20\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.trans1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = x.view(-1,10)\n",
        "\n",
        "        return F.log_softmax(x,dim=1)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xdydjYTZFyi3",
        "outputId": "eacba4e5-8f78-4200-f6e6-3c598b3871ee"
      },
      "source": [
        "!pip install torchsummary\n",
        "from torchsummary import summary\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "summary(model, input_size=(1, 28, 28))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.7/dist-packages (1.5.1)\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1            [-1, 8, 26, 26]              72\n",
            "              ReLU-2            [-1, 8, 26, 26]               0\n",
            "            Conv2d-3           [-1, 16, 24, 24]           1,152\n",
            "              ReLU-4           [-1, 16, 24, 24]               0\n",
            "            Conv2d-5           [-1, 16, 22, 22]           2,304\n",
            "              ReLU-6           [-1, 16, 22, 22]               0\n",
            "            Conv2d-7            [-1, 8, 22, 22]             128\n",
            "              ReLU-8            [-1, 8, 22, 22]               0\n",
            "         MaxPool2d-9            [-1, 8, 11, 11]               0\n",
            "           Conv2d-10             [-1, 16, 9, 9]           1,152\n",
            "             ReLU-11             [-1, 16, 9, 9]               0\n",
            "           Conv2d-12             [-1, 16, 7, 7]           2,304\n",
            "             ReLU-13             [-1, 16, 7, 7]               0\n",
            "           Conv2d-14             [-1, 16, 5, 5]           2,304\n",
            "             ReLU-15             [-1, 16, 5, 5]               0\n",
            "           Conv2d-16             [-1, 16, 3, 3]           2,304\n",
            "             ReLU-17             [-1, 16, 3, 3]               0\n",
            "           Conv2d-18             [-1, 10, 1, 1]           1,440\n",
            "================================================================\n",
            "Total params: 13,160\n",
            "Trainable params: 13,160\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.45\n",
            "Params size (MB): 0.05\n",
            "Estimated Total Size (MB): 0.50\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TnIArnZJ-OXQ"
      },
      "source": [
        "## The Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UuCk_KKM-Foy",
        "outputId": "a5d35265-e9f9-4232-bf4a-7562ccc42e00"
      },
      "source": [
        "model.eval()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Net(\n",
              "  (conv1): Sequential(\n",
              "    (0): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (5): ReLU()\n",
              "  )\n",
              "  (trans1): Sequential(\n",
              "    (0): Conv2d(16, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (conv2): Sequential(\n",
              "    (0): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (1): ReLU()\n",
              "    (2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (3): ReLU()\n",
              "    (4): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (5): ReLU()\n",
              "    (6): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "    (7): ReLU()\n",
              "    (8): Conv2d(16, 10, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ukLGDPFg-LNr"
      },
      "source": [
        "## Model Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVv5BP_c-IZ8",
        "outputId": "c062d8de-61bb-4469-d6cc-2bec8f0ecc66"
      },
      "source": [
        "def count_parameters(model):\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f'The model has {count_parameters(model):,} trainable parameters')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The model has 13,160 trainable parameters\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5h0khHDE8oz8"
      },
      "source": [
        "## Load and Prepare Dataset\n",
        "\n",
        "MNIST contains 70,000 images of handwritten digits: 60,000 for training and 10,000 for testing. The images are grayscale, 28x28 pixels\n",
        "\n",
        "We load the PIL images using torchvision.datasets.MNIST, while loading the image we transform he data to tensor and normalize the images with mean and std deviation of MNIST images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqTWLaM5GHgH"
      },
      "source": [
        "torch.manual_seed(1)\n",
        "batch_size = 128\n",
        "\n",
        "kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}\n",
        "train = datasets.MNIST('../data', train=True, download=True,\n",
        "                    transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]))\n",
        "\n",
        "test = datasets.MNIST('../data', train=False, transform=transforms.Compose([\n",
        "                        transforms.ToTensor(),\n",
        "                        transforms.Normalize((0.1307,), (0.3081,))\n",
        "                    ]))\n",
        "train_loader = torch.utils.data.DataLoader(train, batch_size=batch_size, shuffle=True, **kwargs)\n",
        "test_loader = torch.utils.data.DataLoader(test, batch_size=batch_size, shuffle=False, **kwargs)\n"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7uA-_b5-V4d"
      },
      "source": [
        "## Training and Testing Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pqEfy6VKScEL"
      },
      "source": [
        "from tqdm import tqdm\n",
        "def train(model, device, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    epoch_loss=0\n",
        "    correct = 0\n",
        "    pbar = tqdm(train_loader)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.nll_loss(output, target)\n",
        "        epoch_loss += loss.item()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "        pbar.set_description(desc= f'epoch={epoch} Loss={loss.item()} batch_id={batch_idx:05d}')\n",
        "\n",
        "\n",
        "    train_loss = epoch_loss / len(train_loader.dataset)\n",
        "\n",
        "    print('Train set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        train_loss, correct, len(train_loader.dataset),\n",
        "        100. * correct / len(train_loader.dataset)))\n",
        "    train_acc=100.*correct/len(train_loader.dataset)\n",
        "    return train_loss,train_acc\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            test_loss += F.nll_loss(output, target, reduction='sum').item()  # sum up batch loss\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # get the index of the max log-probability\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "\n",
        "    print('Test set: Average loss: {:.4f}, Accuracy: {}/{} ({:.2f}%)\\n'.format(\n",
        "        test_loss, correct, len(test_loader.dataset),\n",
        "        100. * correct / len(test_loader.dataset)))\n",
        "    test_acc=100. * correct / len(test_loader.dataset)\n",
        "    return test_loss,test_acc"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCTPjqWF-hj6"
      },
      "source": [
        "## Let's write train and test the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KHZxrozQSc2r",
        "outputId": "2402f5c1-3850-4bad-cde4-f9b8d77bb695"
      },
      "source": [
        "model =  Net().to(device)\n",
        "optimizer = optim.SGD(model.parameters(), lr=0.015, momentum=0.9)\n",
        "EPOCHS = 15\n",
        "for epoch in range(EPOCHS):\n",
        "    print(\"EPOCH:\", epoch)\n",
        "    train(model, device, train_loader, optimizer, epoch)\n",
        "    test(model, device, test_loader)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "EPOCH: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=0 Loss=0.40941500663757324 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.54it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0115, Accuracy: 28492/60000 (47.49%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.2381, Accuracy: 9263/10000 (92.63%)\n",
            "\n",
            "EPOCH: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=1 Loss=0.0890578106045723 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 41.17it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0011, Accuracy: 57372/60000 (95.62%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0919, Accuracy: 9708/10000 (97.08%)\n",
            "\n",
            "EPOCH: 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=2 Loss=0.02848839946091175 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.57it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0007, Accuracy: 58425/60000 (97.38%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0626, Accuracy: 9804/10000 (98.04%)\n",
            "\n",
            "EPOCH: 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=3 Loss=0.0331714004278183 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.67it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0005, Accuracy: 58811/60000 (98.02%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0484, Accuracy: 9851/10000 (98.51%)\n",
            "\n",
            "EPOCH: 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=4 Loss=0.02803972363471985 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 41.31it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0004, Accuracy: 59004/60000 (98.34%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0549, Accuracy: 9829/10000 (98.29%)\n",
            "\n",
            "EPOCH: 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=5 Loss=0.029558664187788963 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.41it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0004, Accuracy: 59117/60000 (98.53%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0449, Accuracy: 9855/10000 (98.55%)\n",
            "\n",
            "EPOCH: 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=6 Loss=0.043841246515512466 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.71it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0003, Accuracy: 59192/60000 (98.65%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0413, Accuracy: 9880/10000 (98.80%)\n",
            "\n",
            "EPOCH: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=7 Loss=0.04157417640089989 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.43it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0003, Accuracy: 59280/60000 (98.80%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0433, Accuracy: 9864/10000 (98.64%)\n",
            "\n",
            "EPOCH: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=8 Loss=0.0003563484351616353 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.85it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0003, Accuracy: 59315/60000 (98.86%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0498, Accuracy: 9855/10000 (98.55%)\n",
            "\n",
            "EPOCH: 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=9 Loss=0.007792545482516289 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 41.44it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0003, Accuracy: 59369/60000 (98.95%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0490, Accuracy: 9849/10000 (98.49%)\n",
            "\n",
            "EPOCH: 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=10 Loss=0.00971674919128418 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.96it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0002, Accuracy: 59403/60000 (99.00%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0328, Accuracy: 9900/10000 (99.00%)\n",
            "\n",
            "EPOCH: 11\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=11 Loss=0.0062074740417301655 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 41.07it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0002, Accuracy: 59450/60000 (99.08%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0391, Accuracy: 9876/10000 (98.76%)\n",
            "\n",
            "EPOCH: 12\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=12 Loss=0.021829964593052864 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.22it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0002, Accuracy: 59513/60000 (99.19%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0357, Accuracy: 9883/10000 (98.83%)\n",
            "\n",
            "EPOCH: 13\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=13 Loss=0.003929933067411184 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.88it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0002, Accuracy: 59551/60000 (99.25%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/469 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0430, Accuracy: 9861/10000 (98.61%)\n",
            "\n",
            "EPOCH: 14\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "epoch=14 Loss=0.052546340972185135 batch_id=00468: 100%|██████████| 469/469 [00:11<00:00, 40.49it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train set: Average loss: 0.0002, Accuracy: 59561/60000 (99.27%)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test set: Average loss: 0.0481, Accuracy: 9855/10000 (98.55%)\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huAgWlxP8TXR"
      },
      "source": [
        "## Observation:\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}