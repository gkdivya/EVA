# ViT - An Image is worth 16x16 words

Transformers was primarily built to solve natural language processing tasks. Pretrained models are available for translation, text generation, summarization and more. The models can be downloaded and fine tuned in your deep learning framework of choice as it plays nicely with Tensorflow, Pytorch and Jax.

Transformers aren't just for text any more- they can handle a huge range of input types, and there's been a flurry of papers and new models in the last few months applying them to vision tasks that had traditionally been dominated by convolutional networks.

Here we will be appying ViT or Vision Transformer to train and classify the famous cats and dogs classification dataset  and also, explaining the ViT code block by block.


![image](https://user-images.githubusercontent.com/42609155/127629833-4cc5b520-0c13-4a8a-82cd-b82b9c2d731d.png)


## Collaborators
- Divya Kamat (divya.r.kamat@gmail.com)
- Divya G K (gkdivya@gmail.com)
- Sarang (jaya.sarangan@gmail.com)
- Garvit Garg (garvit.gargs@gmail.com)

